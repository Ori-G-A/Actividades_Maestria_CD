# Procesamiento

-   Vamos Leer el archivo de datos *data_actividad1*

```{r, results = "hide"}
data_act1 <- read_xlsx("data/data_actividad1.xlsx")
```

## Resumen estadístico

La Tabla \@ref(tab:resumenestadistico) presenta un resumen de las principales estadísticas descriptivas para las variables numéricas del dataset, incluyendo medidas de tendencia central, dispersión y el número de datos faltantes por variable.

```{r resumenestadistico}


# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR ESTADÍSTICAS DESCRIPTIVAS
# -------------------------------------------------------------------------

# Se define una función que calcula medidas de tendencia central y dispersión
# para una variable numérica específica.
# La función recibe:
# - variable: vector numérico
# - nombre_variable: nombre de la variable (como texto)

resumen_estadistico <- function(variable, nombre_variable){
  tibble(
    Variable = nombre_variable, 
    # Nombre de la variable analizada
    
    Min = min(variable, na.rm = TRUE),
    # Valor mínimo observado (excluyendo NA)
    
    Max = max(variable, na.rm = TRUE),
    # Valor máximo observado (excluyendo NA)
    
    Median = median(variable, na.rm = TRUE),
    # Mediana (medida robusta de tendencia central)
    
    Media = round(mean(variable, na.rm = TRUE), 2),
    # Media aritmética (redondeada a 2 decimales)
    
    std = round(sd(variable, na.rm = TRUE), 2),
    # Desviación estándar (medida de dispersión)
    
    Q_1 = quantile(variable, 0.25, na.rm = TRUE),
    # Primer cuartil (25%)
    
    Q_3 = quantile(variable, 0.75, na.rm = TRUE)
    # Tercer cuartil (75%)
  )
}

# -------------------------------------------------------------------------
# IDENTIFICAR VARIABLES NUMÉRICAS DEL DATASET
# -------------------------------------------------------------------------

columnas_numericas <- names(data_act1)[sapply(data_act1, is.numeric)]
# sapply(..., is.numeric) identifica qué columnas son numéricas
# names(...) devuelve los nombres de dichas columnas

# -------------------------------------------------------------------------
# APLICAR FUNCIÓN A CADA VARIABLE NUMÉRICA
# -------------------------------------------------------------------------

estadisticas <- bind_rows(
  lapply(columnas_numericas, function(col) {
    resumen_estadistico(data_act1[[col]], col)
  })
)
# lapply recorre cada columna numérica
# bind_rows une todos los resultados en una sola tabla

# -------------------------------------------------------------------------
# CÁLCULO DE DATOS FALTANTES
# -------------------------------------------------------------------------

# colSums(is.na()) cuenta el número de NA por variable
# Se convierte en data frame y se agrega el nombre de la variable como columna
faltantes <- colSums(is.na(data_act1)) %>% 
  as.data.frame() %>%
  tibble::rownames_to_column("Variable")



# Se renombran las columnas para mayor claridad
colnames(faltantes) <- c("Variable", "NA's")


# -------------------------------------------------------------------------
# UNIÓN DE ESTADÍSTICAS Y DATOS FALTANTES
# -------------------------------------------------------------------------

tabla_completa <- left_join(estadisticas, faltantes, by = "Variable")
# left_join combina ambas tablas usando el nombre de la variable como clave

# -------------------------------------------------------------------------
# PRESENTACIÓN DE LA TABLA
# -------------------------------------------------------------------------

kable(tabla_completa, format = "html", 
      caption = "Estadísticas descriptivas y datos faltantes") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)

# Se genera una tabla formateada con:
# - Medidas descriptivas
# - Cantidad de valores faltantes
```

A continuación, se procederá con una revisión detallada de valores faltantes, datos atípicos e inconsistencias. Sin embargo, desde esta primera visualización ya emergen algunos aspectos relevantes que merecen atención.

En primer lugar, resulta llamativa la magnitud de la desviación estándar en la variable *Income*, así como en todas aquellas variables cuyo nombre inicia con *Mnt*, lo que sugiere una alta dispersión en los ingresos reportados y en los niveles de gasto, especialmente en el caso de las variables de gasto específico. Esta variabilidad se refleja también en la diferencia observable entre media y mediana, lo cual podría indicar la presencia de asimetrías positivas.

Particularmente en *Income*, se observa una diferencia cercana al millón entre el valor mínimo y el máximo. Además, esta variable, junto con *MntWines*, son las únicas que presentan valores nulos, lo que sugiere que el tratamiento de datos faltantes deberá considerarse con especial cuidado en el análisis posterior.

Otro aspecto relevante es que *MntRegularProds* es la única variable cuyo valor mínimo es negativo, lo que podría indicar un posible error de registro, ajustes contables o devoluciones que deben ser verificados en etapas posteriores del análisis de calidad de datos.

Así mismo, la variable *marital_Divorced* tenga como valor valor máximo 100. Esto teniendo en cuenta que, junto a las otras variables relacionadas al estado civil, fue clasificada como variable cualitativa binaria, por lo que se presume un error de registo.

También, llama la atención que *AcceptedCmpOverall* presenta tiene como mediana el valor 0.0, lo que podría sugerir que, en su gran mayoría, los cientes contactados no respondieron de manera positiva a ninguna de las 5 campañas anteriores.

Finalmente, dentro de las variables de gasto específico, se observa que *MntWines* y *MntMeatProducts* son las únicas que presentan valores máximos superiores a 1000 unidades monetarias, lo que podría señalar categorías de consumo con alta concentración de gasto en determinados clientes.

## Identificación y eliminación de duplicados

En esta etapa se procede a verificar la existencia de registros duplicados en el dataset, con el objetivo de garantizar que cada fila represente una observación única.

```{r tabladuplicados }
# Identificamos los duplicados
total_datos <- nrow(data_act1)
duplicados <- duplicated(data_act1)
total_duplicados <- sum(duplicados)

# Eliminar duplicados
data_sin_dup <- data_act1[!duplicados, ]

# Tabla con información de duplicados en formato vertical
resumen_duplicados <- data.frame(
  Concepto = c(
    "Total de datos original",
    "Total de duplicados",
    "Porcentaje de duplicados (%)",
    "Total de datos sin duplicados"
  ),
  Valor = c(
    total_datos,
    total_duplicados,
    paste(round(total_duplicados/nrow(data_act1)  * 100, 2), "%"),
    nrow(data_sin_dup)
  )
)
# danmos formato a la tabla de reporte de duplicados
knitr::kable(
  resumen_duplicados,
  caption = "Detección y eliminación de duplicados",
  label = "tabladuplicados",
  col.names = c("Concepto", "Valor"),
  align = c("l", "l")
)

```

```{r eliminacion_duplicados, include=FALSE}

# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET DEPURADO
# -------------------------------------------------------------------------
write.csv(
  data_sin_dup,
  file = "data_limpia/data_sin_duplicados.csv",
  row.names = FALSE
)
# Se exporta el nuevo dataset limpio en formato CSV
```

La Tabla \@ref(tab:tabladuplicados) muestra que inicialmente se contaba con 2220 observaciones, de las cuales 179 correspondían a registros duplicados representando el 8.06 % del total de registros. Tras su eliminación, el conjunto de datos quedó conformado por 2041 registros únicos.

```{r carga_dataset_limpio}
data_act1 <- read.csv("data_limpia/data_sin_duplicados.csv")
# Se reemplaza el dataset original por la versión depurada
```

Veamos el resumen estadístico del nuevo dataset en la tabla \@ref(tab:resumenpostlimpieza)

```{r resumenpostlimpieza}
# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR ESTADÍSTICAS DESCRIPTIVAS
# -------------------------------------------------------------------------

resumen_estadistico <- function(variable, nombre_variable){
  tibble(
    Variable = nombre_variable,
    Min = min(variable, na.rm = TRUE),
    Max = max(variable, na.rm = TRUE),
    Median = median(variable, na.rm = TRUE),
    Media = round(mean(variable, na.rm = TRUE), 2),
    std = round(sd(variable, na.rm = TRUE), 2),
    Q_1 = quantile(variable, 0.25, na.rm = TRUE),
    Q_3 = quantile(variable, 0.75, na.rm = TRUE)
  )
}

# Identificación de columnas numéricas
columnas_numericas <- names(data_act1)[sapply(data_act1, is.numeric)]

# Aplicación de la función a cada variable numérica
estadisticas <- bind_rows(
  lapply(columnas_numericas, function(col) {
    resumen_estadistico(data_act1[[col]], col)
  })
)

# Cálculo de valores faltantes
faltantes <- colSums(is.na(data_act1)) %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Variable")

colnames(faltantes) <- c("Variable", "NA's")

# Unión de estadísticas descriptivas y faltantes
tabla_completa <- left_join(estadisticas, faltantes, by = "Variable")

# Presentación de la tabla
kable(tabla_completa, format = "html",
      caption = "Estadísticas descriptivas y datos faltantes (post eliminación de duplicados)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"),
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

Tomando como referencia los aspectos clave presentados en la Tabla \@ref(tab:resumenestadistico), y tras contrastarlos con la información contenida en la Tabla \@ref(tab:resumenpostlimpieza), se concluye que no se produjo cambios observaron cambios significativos tras la eliminación de los registros duplicados. Únicamente se evidenciaron ligeras variaciones en algunas medidas de tendencia central, sin modificaciones en los valores mínimos, máximos ni en la cantidad de datos faltantes. Asimismo, los patrones previamente identificados (como la alta dispersión en *Income* y en las variables de gasto, así como la presencia de valores extremos) se mantienen.

Esto sugiere que los registros duplicados no estaban concentrados en perfiles atípicos ni alteraban de forma sustancial la estructura descriptiva del dataset, sino que se encontraban distribuidos de manera relativamente homogénea.

## Errores e inconsistencias

### Identificación de valores atípicos para variables cualitativas binarias

A continuación, se analizan las variables cualitativas binarias con el objetivo de detectar posibles inconsistencias, categorías inesperadas o desbalances extremos en las frecuencias.

```{r seleccion_binarias}
# -------------------------------------------------------------------------
# SELECCIÓN DE VARIABLES CUALITATIVAS BINARIAS
# -------------------------------------------------------------------------

variables_binarias <- data_act1 %>%
  
# Se seleccionan explícitamente las variables binarias del dataset.
# Estas corresponden a indicadores de respuesta a campañas,
# nivel educativo y estado civil.
  
  dplyr::select(AcceptedCmp1,AcceptedCmp2,AcceptedCmp3,AcceptedCmp4,AcceptedCmp5, Response, Complain,
    education_2n.Cycle,education_Basic,education_Graduation,
    education_Master,education_PhD,
    marital_Divorced,marital_Married,marital_Single,
    marital_Together, marital_Widow)


```

Posteriormente, se construyen diagramas de barras para visualizar la distribución de frecuencias de cada variable binaria y realizar un análisis gráfico que permita identificar las variables que aporten información relevante y las que requieran un tratamiento especial.

```{r barplotbinarias, fig.cap="Distribución de variables binarias", fig.height=40, fig.width=14}

# -------------------------------------------------------------------------
# VISUALIZACIÓN DE FRECUENCIAS PARA VARIABLES BINARIAS
# -------------------------------------------------------------------------

# Vector con los nombres de las variables binarias
vars_binarias <- c("AcceptedCmp1", "AcceptedCmp2","AcceptedCmp3","AcceptedCmp4",
                   "AcceptedCmp5","Response","Complain","marital_Single",
                   "marital_Together", "marital_Married","marital_Divorced",
                   "marital_Widow", "education_Basic", "education_2n.Cycle",
                   "education_Graduation", "education_Master", "education_PhD")


# Se genera una lista de gráficos, uno por cada variable
lista_graficos <- lapply(seq_along(vars_binarias), function(i) {
  var <- vars_binarias[i]
  
 # Cálculo de frecuencias absolutas
  tabla_freq <- data_act1 %>%
    count(!!sym(var)) %>%
    rename(Categoria = 1, Frecuencia = n) %>%
    mutate(Categoria = factor(Categoria, levels = c(0, 1), labels = c("No", "Sí")))
  
  # Construcción del gráfico de barras
  ggplot(tabla_freq, aes(x = Categoria, y = Frecuencia, fill = Categoria)) +
    geom_bar(stat = "identity", alpha = 1, color = "grey20", linewidth = 0.5, show.legend = FALSE) +
    geom_text(aes(label = Frecuencia), vjust = -0.5, size = 4, fontface = "bold") +
    scale_fill_manual(values = c("No" = "pink", "Sí" = "#BAC095")) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 10, face = "bold"),
      plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
      panel.grid.major.x = element_blank()
    ) +
    labs(
      title = var,
      x = "",
      y = "Frecuencia"
    ) +
    ylim(0, max(tabla_freq$Frecuencia) * 1.15)
})

# Organización de los gráficos en una cuadrícula de dos columnas
do.call(grid.arrange, c(lista_graficos, ncol = 2))
```

El análisis gráfico obtenido de la Figura \@ref(fig:barplotbinarias) permite identificar varios patrones relevantes en las variables binarias.

En primer lugar, la respuesta de los clientes a las campañas 1 a la 5 fue considerablemente baja oscilando entre 27 y 158 respuestas afirmativas. En contraste, la campaña piloto presenta 314 respuestas positivas, lo que sugiere una mejora sustancial en la efectividad de la estrategia implementada o en la segmentación utilizada para su ejecución.

En relación con la variable *Complain*, únicamente se registran 19 quejas, lo que evidencia una baja proporción de inconformidades. Este resultado podría interpretarse como un indicador favorable en términos de calidad del servicio y satisfacción del cliente; sin embargo, también conviene verificar que el proceso de registro de quejas sea exhaustivo y consistente.

Respecto al estado civil, se observa que la mayoría de los clientes se encuentran casados o conviven en unión libre. No obstante, llama la atención que para 6 clientes aparece una tercera respuesta en la categoría *marital_Divorced*, que como se había mencionado en el estudio del resumen estadístico está codificada con el valor 100. Dado que se trata de una variable binaria, la presencia de un valor distinto de 0 y 1 constituye una inconsistencia que debe ser corregida.

En cuanto al nivel educativo, aproximadamente la mitad de los clientes (1023) cuentan con título universitario, lo que sugiere un perfil educativo relativamente alto dentro de la muestra.

### Identificación de valores atípicos para variables discretas

En esta sección se identifican posibles valores atípicos en las variables cuantitativas discretas del conjunto de datos. Para ello, se emplea el criterio basado en el rango intercuartílico (IQR).

```{r atipicasdiscretas, }
# Función para detectar valores atípicos mediante el criterio del IQR
# Recibe como argumento un vector numérico (var)

detectar_atipicos <- function(var){
  # Calcula los cuartiles Q1 (25%) y Q3 (75%) ignorando valores NA
  Q1 <- quantile(var,0.25,na.rm = TRUE)
  Q3 <- quantile(var,0.75,na.rm = TRUE)
  # Determina el rango intercuartílico (IQR = Q3 - Q1)
  IQR <- Q3-Q1
  # Retorna las posiciones (índices) de los valores que se encuentran por debajo de Q1 - 1.5*IQR o por encima de Q3 + 1.5*IQR
  which(var < (Q1-1.5*IQR) | var > (Q3+1.5*IQR))
}

# Selección de variables cuantitativas discretas desde el dataset principal
variables_discretas <- data_act1 %>%
  
# Se extraen variables relacionadas con composición del hogar, historial de campañas y frecuencia de compras en distintos canales
dplyr::select(Kidhome, Teenhome, Age, Recency, Customer_Days,   AcceptedCmpOverall, NumDealsPurchases, NumCatalogPurchases, NumStorePurchases,  NumWebPurchases, NumWebVisitsMonth)


# Identificación de valores atípicos por variable
# lapply aplica la función detectar_atipicos a cada columna
# El resultado es una lista donde cada elemento contiene las posiciones de los valores atípicos por variable

atipicos_d <- lapply(variables_discretas, detectar_atipicos)
```

La Tabla \@ref(tab:tablaatipicosdiscretos) indica el número total de valores atípicos encontrados en cada variable. Esto permite evaluar rápidamente cuáles presentan mayor concentración de observaciones extremas.

```{r tablaatipicosdiscretos, }
# Construcción de tabla resumen de valores atípicos

tabla_atipicos_d <- data.frame(
  # names(atipicos_d) extrae los nombres de las variables
  variable = names(atipicos_d),
  # sapply(..., length) calcula cuántos atípicos tiene cada variable
  total_atipicos_d = sapply(atipicos_d, length),
  stringsAsFactors = FALSE
  # Se crea un data.frame con el total por variable
)


# Creación de tabla con formato HTML usando kable
# Se agrega título y estilo visual para mejorar la presentación del informe
kable(tabla_atipicos_d, format = "html", 
      caption = "Tabla de valores atípicos por variable") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

Al analizar la distribución de valores atípicos en la Tabla \@ref(tab:tablaatipicosdiscretos) se observa que la variable Age presenta únicamente 2 observaciones extremas (≈0.1% del total).

En variables asociadas al comportamiento de compra y navegación (NumWebPurchases y NumWebVisitsMonth) se identifican menos de 10 valores atípicos en cada caso (menos del 0.5% de la muestra). Estos registros podrían corresponder a clientes con una actividad comercial particularmente intensa, pero no constituyen una proporción preocupante desde el punto de vista estadístico.

Por su parte, NumDealsPurchases (compras en oferta) registra 74 valores atípicos (≈3.6%), mientras que NumCatalogPurchases presenta 19 (≈0.9%). En el primer caso, la magnitud sugiere la posible existencia de un subgrupo de clientes altamente sensibles a promociones.

El resultado más llamativo corresponde a AcceptedCmpOverall, con 431 valores atípicos (≈21.1% de la muestra).

Con el fin de emitir un juicio más preciso sobre estos casos, se realiza a continuación una inspección visual mediante diagramas de caja (boxplots) para cada variable discreta.

```{r boxplotdiscreta, fig.cap="Distribución de variables discretas", fig.height=20}
vars <- names(variables_discretas)

plots_list <- lapply(vars, function(var) {
  ggplot(data_act1, aes(y = .data[[var]])) +
    geom_boxplot(fill = "pink", alpha = 0.7,
                 median.colour = "firebrick") +
    labs(
      title = paste("Boxplot de", var),
      y = var
    ) +
    theme_minimal()
})

wrap_plots(plots_list, ncol = 2)
```

La inspección visual de los diagramas de caja en la Figura \@ref(fig:boxplotdiscreta) permite complementar la lectura obtenida a partir del criterio del rango intercuartílico (IQR) y aportar mayor claridad sobre la naturaleza de los valores identificados como atípicos.

En el caso de la variable *Age*, los valores extremos detectados corresponden a edades superiores a 200 años. Desde una perspectiva demográfica, estos registros son imposibles en términos de expectativa de vida humana, por lo que no pueden interpretarse como comportamientos extremos plausibles, sino como errores evidentes en los datos. En consecuencia, estos casos requieren corrección o depuración antes de cualquier análisis posterior.

Por su parte, en *AcceptedCmpOverall* se observa una fuerte concentración en el valor 0. Visualmente, no se aprecia una caja definida; únicamente se distingue la línea correspondiente a la mediana, ubicada en 0, junto con cuatro puntos aislados en las alturas 1, 2, 3 y 4. Esta configuración gráfica confirma lo mencionado durante la inspección de las estadísticas del dataset: que la mayoría de los clientes no aceptaron campañas, lo que hace que aceptar una o más campañas constituya un comportamiento poco frecuente dentro del conjunto de datos.

Una situación similar se observa en *NumDealsPurchases* y *NumCatalogPurchases*, cuyas distribuciones también se encuentran fuertemente concentradas en valores cercanos a cero. La cercanía de la caja al origen y la presencia de algunos valores superiores aislados sugieren que la mayoría de los clientes realiza pocas compras en oferta o por catálogo, mientras que un grupo reducido presenta una actividad más intensa en estos canales.

En conjunto, los boxplots evidencian que, salvo en el caso de *Age*, los valores identificados como atípicos responden principalmente a distribuciones discretas con alta concentración en cero y marcada asimetría positiva.

### Identificación de valores atípicos para variables continuas

Finalmente, se analiza la presencia de valores atípicos en las variables cuantitativas continuas, principalmente asociadas a ingresos y montos de gasto por categoría de producto.

```{r tablaatipicoscontinuas}

# Selección de variables cuantitativas continuas desde el dataset principal
# Se incluyen variables de ingreso (Income) y montos de gasto por categoría
# así como variables agregadas de gasto total y gasto regular

variables_continuas <- data_act1 %>%
  dplyr::select(Income, MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds,  MntTotal, MntRegularProds)

# Identificación de valores atípicos por variable continua
# lapply aplica la función detectar_atipicos a cada columna seleccionada. El resultado es una lista con los índices de observaciones atípicas


atipicos_c <- lapply(variables_continuas, detectar_atipicos)

# Construcción de tabla resumen de valores atípicos



tabla_atipicos_c <- data.frame(
  # names(atipicos_c) extrae los nombres de las variables
  variable = names(atipicos_c),
  # sapply(..., length) calcula la cantidad de atípicos por variable
  total_atipicos_c = sapply(atipicos_c, length),
  # Se organiza la información en un data.frame para su presentación
  stringsAsFactors = FALSE
)

# Creación de tabla con formato HTML usando kable
# Se agrega título y formato visual para su integración en el informe
kable(tabla_atipicos_c, format = "html", 
      caption = "Tabla de valores atípicos por variable") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

En el estudio de la Tabla \@ref(tab:resumenestadistico) se señaló que, dentro de las variables de gasto específico, *MntWines* y *MntMeatProducts* eran las únicas que presentaban valores máximos superiores a 1000 unidades monetarias, lo que podía indicar categorías con alta concentración de gasto en determinados clientes.

Sin embargo, el análisis formal de valores atípicos mediante el criterio del rango intercuartílico (IQR) de la Tabla \@ref(tab:tablaatipicoscontinuas) muestra un comportamiento diferente al esperado. Las variables con mayor número de observaciones extremas no son necesariamente aquellas con los máximos absolutos más elevados. En particular, *MntFruits*, *MntFishProducts* y *MntSweetProducts* registran más de 200 valores atípicos cada una.

Este resultado sugiere que, aunque los montos máximos en estas categorías no superen los de vinos o carnes, su distribución presenta una asimetría importante y una fuerte concentración en valores bajos, lo que provoca que los consumos relativamente altos queden rápidamente por fuera del rango intercuartílico.

En segundo lugar, se encuentra *MntMeatProducts*, con 170 valores atípicos. Este comportamiento resulta coherente con lo anticipado en el análisis descriptivo, dado que se trata de una categoría con altos montos máximos y, por tanto, mayor dispersión potencial.

La única variable de esta naturaleza que no presenta datos atípicos es *Income*

Con el fin de emitir un juicio más preciso sobre estos casos, se realiza a continuación una inspección visual mediante diagramas de caja (boxplots) para cada variable continua.

```{r boxplotcontinuas, fig.cap="Distribución de variables continuas", fig.height=20}
vars <- names(variables_continuas)

plots_list <- lapply(vars, function(var) {
  ggplot(data_act1, aes(y = .data[[var]])) +
    geom_boxplot(fill = "pink", alpha = 0.7,
                 median.colour = "firebrick") +
    labs(
      title = paste("Boxplot de", var),
      y = var
    ) +
    theme_minimal()
})

wrap_plots(plots_list, ncol = 2)
```

Al revisar los diagramas de caja de la Figura \@ref(fig:boxplotcontinuas) notamos que todas las cajas de las variables de gasto que inician con *Mnt* se concentran en la parte inferior de la figura. Este comportamiento indica una fuerte acumulación de observaciones en niveles bajos de gasto, acompañada de colas superiores extendidas que reflejan consumos elevados en un grupo reducido de clientes.

La única excepción parcial es *MntRegularProds*, cuyo eje se extiende ligeramente más hacia la parte inferior debido a la presencia de valores negativos previamente detectados en la Tabla \@ref(tab:resumenestadistico).

La concentración de las cajas en la zona baja del gráfico sugiere que, la mayoría de las categorías de producto estudiadas no son consumidos de manera homogénea por la totalidad de los clientes, es decir, una proporción importante de clientes presenta gasto nulo o reducido. Esto implica que los valores identificados como atípicos no necesariamente representan anomalías, sino que más bien un subconjunto de clientes actúa como consumidor habitual o intensivo en cada categoría, aspecto que, de hecho, ayudaría mucho en la tarea de análisis y segmentación de los clientes.

## Solución de inconsistencias

Con base en los hallazgos obtenidos en el análisis descriptivo y en la detección de valores atípicos, se procede a identificar formalmente registros inconsistentes en variables específicas mendiante la tabla \@ref(tab:tabinconsistencia).

```{r tabinconsistencia}
inconsistencias <- tibble(
  Variable = c("MntRegularProds", "Age", "marital_Divorced"),
  Registros_invalidos = c(
    sum(data_act1$MntRegularProds < 0, na.rm = TRUE),
    sum(data_act1$Age <= 0 | data_act1$Age > 110, na.rm = TRUE),
    sum(!data_act1$marital_Divorced %in% c(0,1), na.rm = TRUE)
  ),
  Valores_invalidos = c(
    paste(unique(data_act1$MntRegularProds[
      data_act1$MntRegularProds < 0
    ]), collapse = ", "),
    
    paste(unique(data_act1$Age[
      data_act1$Age <= 0 | data_act1$Age > 110
    ]), collapse = ", "),
    
    paste(unique(data_act1$marital_Divorced[
      !data_act1$marital_Divorced %in% c(0,1)
    ]), collapse = ", ")
  )
)

knitr::kable(
  inconsistencias,
  caption = "Cantidad y valores de registros inconsistentes por variable",
  align = c("l", "c", "l")
)

```

### Inspección y depuración de la variable *marital_Divorced*

Dado que se detectaron valores fuera del dominio esperado (0 y 1) en *marital_Divorced*, se realiza una inspección detallada de sus categorías en la Figura \@ref(fig:divorcedF).

```{r divorcedF, fig.cap="Distribución de Estado de Divorcio"}
# Crear tabla de frecuencias y ordenar manualmente
data_act1_temp <- data_act1 %>%
  mutate(Estado_Divorcio = case_when(
    marital_Divorced == 0 ~ "No Divorciado",
    marital_Divorced == 1 ~ "Divorciado",
    marital_Divorced == 100 ~ "Error (100)",
    TRUE ~ "Otro"
  )) %>%
  count(Estado_Divorcio) %>%
  arrange(desc(n)) %>%
  mutate(Estado_Divorcio = factor(Estado_Divorcio, levels = Estado_Divorcio))

# Gráfico
ggplot(data_act1_temp, aes(x = Estado_Divorcio, y = n)) +
  geom_col(fill = "pink", color = "black", width = 0.3) +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(title = "Distribución de Estado de Divorcio",
       x = "Estado",
       y = "Frecuencia") +
  theme_minimal()
```

Posteriormente, se construye la Tabla \@ref(tab:divorcetab) que permiten visualizar la distribución de los valores en las variables relacionadas al estado civil sólo en los registros que contienen el valor 100 como posible error de codificación.

```{r divorcetab}
# Ver registros con valor 100
auditar_estado_civil <- function(data) {
  
  vars_marital <- c(
    "marital_Single",
    "marital_Together",
    "marital_Married",
    "marital_Divorced",
    "marital_Widow"
  )
  
  resultado <- data %>%
    dplyr::mutate(
      suma_marital = rowSums(dplyr::select(., dplyr::all_of(vars_marital)), 
                             na.rm = TRUE)
    ) %>%
    dplyr::filter(suma_marital >= 100) %>%
    dplyr::select(dplyr::all_of(vars_marital), )
  
  return(resultado)
  }

tabla_marital_inconsistente <- auditar_estado_civil(data_act1)

knitr::kable(
  tabla_marital_inconsistente,
  caption = "Registros con valor anómalo en variables de estado civil",
  align = "c",
  full_width = TRUE
)
```

Dado que en el resto de variables dummy de estado civil los valores posibles son 0 o 1, y que por definición el estado civil de cada cliente debe tomar el valor 1 en **una sola** de las variables indicadoras, puede concluirse que el valor 100 observado en *marital_Divorced* corresponde a un error de digitación. No existe una justificación lógica ni estructural para que esta variable adopte dicho valor dentro del esquema de codificación binaria.

En consecuencia, y priorizando la integridad estructural del conjunto de datos (es decir, preservando la coherencia del sistema de variables dummy sin eliminar registros, mientras sea posible) se procede a reemplazar el valor 100 por 1.

```{r correccion-marital-divorced}
# Corrección del error de codificación en marital_Divorced
# Se reemplaza el valor 100 por 1

data_act1 <- data_act1 %>%
  mutate(
    marital_Divorced = ifelse(marital_Divorced == 100, 1, marital_Divorced)
  )
```

Para evaluar el impacto de esta corrección, se comparan las proporciones antes y después del ajuste.

Antes de la corrección, la distribución era la siguiente:

* 1826 registros con valor 0 (≈ 89.47%)
* 209 registros con valor 1 (≈ 10.24%)
* 6 registros con valor 100 (≈ 0.29%)

Tras la corrección, la distribución pasa a ser:

* 1826 registros con valor 0 (≈ 89.47%)
* 215 registros con valor 1 (≈ 10.53%)

El incremento en la proporción de clientes clasificados como divorciados es de apenas 0.29 puntos porcentuales, lo que constituye una variación mínima. Es decir, este cambio es demasiado pequeño para suponer una alteración significativa en la estructura de la variable *marital_Divorced*, de manera que, la corrección preserva la coherencia interna de las variables de estado civil sin introducir distorsiones relevantes en la distribución original.

### Inspección y depuración de la variable *Age*

En la revisión preliminar (ver Tabla \@ref(tab:tabinconsistencia)), se identificaron 2 registros con valor 240 en la variable *Age*, valor que excede claramente el rango biológicamente plausible para la edad humana.

```{r inspedades, fig.cap = "Distribución de la variable Edad con histograma y curva de densidad"}
dist_edades <- ggplot(data_act1, aes(x = Age)) +
    geom_histogram(aes(y = after_stat(density)), bins = 40,
                   fill = "pink", color = "black", alpha = 0.7) +
    geom_density(color = "firebrick", linewidth = 0.5) +
    labs(title = "Distribución de Edades",
         x = "Edades",
         y = "Densidad") +
    theme_minimal()

dist_edades
```

Tal como se observa en la Figura \@ref(fig:inspedades), la mayor concentración de edades se acumula aproximadamente entre los 25 y 75 años, con una distribución continua y como se podría comprobar revisando también el boxplot correspondiente en la Figura \@ref(fig:boxplotdiscreta), no hay indicios visuales de valores extremos en el rango superior, salvo los dos casos mencionados.

Si el valor 240 correspondiera a un error de digitación, una hipótesis razonable sería que el valor correcto fuese 24. No obstante, realizar dicha sustitución implicaría introducir un supuesto no verificable, además de modificar potencialmente al menos una de las medidas descriptivas globales del conjunto de datos (mínimo, media, desviación estándar y asimetría).

Dado que únicamente se trata de 2 registros sobre un total de 2041 observaciones (≈ 0.098%), y considerando la urgencia de no alterar innecesariamente los datos originales cuando no existe información adicional que permita una imputación fundamentada, se opta por eliminar dichos registros del conjunto de datos quedando con un total de 2039 registros.


```{r correccion-age, include=FALSE }
# Eliminación de registros con edades no plausibles

data_consistente <- data_act1 %>%
  filter(Age > 0 & Age <= 110)

# Verificación del nuevo tamaño del dataset
nrow(data_consistente)
```



### Inspección y depuración de la variable *MntRegularProds*

En la Tabla \@ref(tab:tabinconsistencia) se identificaron tres valores negativos en la variable *MntRegularProds* (-151, -166 y -283). Dado que esta variable representa un monto de gasto, los valores negativos no resultan coherentes bajo una interpretación directa del indicador.

La Figura \@ref(fig:distmntregularantes) muestra la distribución de la variable. Visualmente, los valores negativos aparecen como observaciones aisladas en el extremo izquierdo de la distribución.

```{r distmntregularantes, fig.cap="Distribución original de MntRegularProds con histograma y curva de densidad"}
ggplot(data_act1, aes(x = MntRegularProds)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50,
                 fill = "pink", color = "black", alpha = 0.7) +
  geom_density(color = "firebrick", linewidth = 1) +
  labs(title = "Distribución de Monto en Productos Regulares",
       x = "Monto (MntRegularProds)",
       y = "Densidad") +
  theme_minimal()
```

Dado que no se dispone de documentación que respalde la hipótesis de devoluciones o ajustes contables, y considerando que se cuenta con el detalle de los montos por tipo de producto, se plantea la hipótesis de que MntRegularProds podría corresponder a:

1. **Monto total menos productos de oro**.
2. **Suma de productos regulares específicos (vinos, frutas, carne, pescado y dulces)**.

Para evitar decisiones arbitrarias, se calcularon ambos métodos únicamente para los registros inconsistentes y se compararon los resultados, donde la decisión metodológica se tomará según el siguiente criterio:

* Si la columna **Diferencia** es igual a 0 en todos los registros, se procederá a recalcular los valores inconsistentes.
* En caso contrario, y ante la imposibilidad de justificar el origen del error, se eliminarán los registros afectados.

```{r tablaverificacionmntregular}
# -------------------------------------------------------------------------
# TABLA COMPARATIVA DE MÉTODOS DE CÁLCULO
# -------------------------------------------------------------------------

verificacion_mnt <- data_act1 %>%
  filter(MntRegularProds < 0) %>%
  mutate(
    Metodo_Total_menos_Oro = (MntWines + MntFruits + MntMeatProducts +
                              MntFishProducts + MntSweetProducts + MntGoldProds) -
                              MntGoldProds,
    Metodo_Suma_Regular = MntWines + MntFruits + MntMeatProducts +
                          MntFishProducts + MntSweetProducts,
    Diferencia = Metodo_Total_menos_Oro - Metodo_Suma_Regular
  ) %>%
  select(Metodo_Total_menos_Oro, Metodo_Suma_Regular, Diferencia)

knitr::kable(
  verificacion_mnt,
  caption = "Comparación de métodos de cálculo para registros con MntRegularProds negativo",
  align = "c"
)
```


Los resultados presentados en la Tabla \@ref(tab:tablaverificacionmntregular) muestran que la columna Diferencia toma valor 0 en los tres registros evaluados. Esto confirma que ambos métodos de cálculo producen exactamente el mismo resultado y, por tanto, valida la hipótesis de que la variable *MntRegularProds* corresponde a la suma de los productos regulares (excluyendo oro).

En consecuencia, se optó por recalcular los valores inconsistentes, preservando así los registros originales y manteniendo la coherencia interna de las variables de gasto.

```{r correccion-mntregular}
# -------------------------------------------------------------------------
# OPCIÓN 1: RECÁLCULO DE LOS VALORES
# -------------------------------------------------------------------------

data_consistente <- data_consistente %>%
  mutate(
    MntRegularProds = ifelse(
      MntRegularProds < 0,
      MntWines + MntFruits + MntMeatProducts +
      MntFishProducts + MntSweetProducts,
      MntRegularProds
    )
  )
```


Dado que únicamente tres observaciones (3/2039) fueron modificadas, se espera que el impacto distributivo sea mínimo. A continuación, se presentan las comparaciones gráficas del dataset original y el dataset corregido .


```{r comparacionmntregularfinal, fig.cap="Distribución comparativa de MntRegularProds antes (rosa) y después (verde) de la corrección"}

# Unificar datasets

datos_comparacion <- bind_rows(
  data_act1 %>% mutate(Dataset = "Antes"),
  data_consistente %>% mutate(Dataset = "Después")
)

# Gráfico combinado: histogramas + densidades

dist_mntregular <- ggplot(datos_comparacion, aes(x = MntRegularProds)) +
  
  # Histogramas con borde por dataset
  geom_histogram(aes(y = after_stat(density),
                     fill = Dataset,
                     color = Dataset),
                 bins = 50,
                 position = "identity",
                 alpha = 0.30,
                 linewidth = 0.6) +
  
  # Densidades solo línea
  geom_density(aes(color = Dataset),
               linewidth = 1.2, alpha=0.5 ) +
  
  scale_fill_manual(values = c("Antes" = "pink",
                               "Después" = "#BAC095")) +
  
  scale_color_manual(values = c("Antes" = "firebrick",
                                "Después" = "#5A6E3A")) +
  
  labs(title = "Comparación de MntRegularProds antes y después de la corrección",
       x = "Monto (MntRegularProds)",
       y = "Densidad",
       fill = "Dataset",
       color = "Dataset") +
  
  theme_minimal()

dist_mntregular


```


En la Figura \@ref(fig:comparacionmntregularfinal) se observa una superposición prácticamente total entre las distribuciones. Incluso con la diferenciación por color y leyenda, no se distinguen variaciones visuales relevantes entre el conjunto original y el corregido.

```{r exportacion-data-consistente, include=FALSE}
# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET DEPURADO
# -------------------------------------------------------------------------
write.csv(
  data_consistente,
  file = "data_limpia/data_consistente.csv",
  row.names = FALSE
)
# Se exporta el nuevo dataset consistente en formato CSV
```


## Identificación de datos faltantes

En esta etapa se cuantifica la presencia de valores nulos en tres momentos clave del proceso de limpieza. Este ejercicio permite verificar si la depuración de duplicados o la corrección de inconsistencias alteraron la estructura de los datos faltantes.

```{r nuloscomparativa, echo=FALSE}
# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR TABLAS DE NULOS
# -------------------------------------------------------------------------

# Se define una función reutilizable que recibe un data frame,
# calcula la cantidad y proporción de valores NA por variable
# y retorna únicamente aquellas variables que presentan al menos un faltante.

calcular_nulos <- function(df) {
  data.frame(
    Variable = names(df),
    Nulos = colSums(is.na(df)),
    Porcentaje = round(colSums(is.na(df)) / nrow(df) * 100, 2)
  ) %>%
    filter(Nulos > 0) %>%
    arrange(desc(Porcentaje))
}

# -------------------------------------------------------------------------
# CÁLCULO DE NULOS EN LAS TRES ETAPAS DEL PROCESO DE LIMPIEZA
# -------------------------------------------------------------------------

# Etapa 1: Dataset original (lectura directa del archivo fuente)
raw_data <- readxl::read_xlsx("data/data_actividad1.xlsx")
tabla_nulos_original <- calcular_nulos(raw_data)

# Etapa 2: Dataset tras la eliminación de duplicados
data_sin_dup <- read.csv("data_limpia/data_sin_duplicados.csv")
tabla_nulos_sin_dup <- calcular_nulos(data_sin_dup)

# Etapa 3: Dataset tras la corrección de inconsistencias
tabla_nulos_consistente <- calcular_nulos(data_consistente)

# -------------------------------------------------------------------------
# CONSTRUCCIÓN DE LA TABLA COMPARATIVA
# -------------------------------------------------------------------------

# Se genera un vector con las variables que presentan faltantes
# en al menos una de las tres etapas

vars_con_na <- unique(c(
  tabla_nulos_original$Variable,
  tabla_nulos_sin_dup$Variable,
  tabla_nulos_consistente$Variable
))

# Se construye la tabla comparativa unificada mediante left_join
# Cada columna representa una etapa del proceso de limpieza

tabla_comparativa_nulos <- data.frame(Variable = vars_con_na) %>%
  left_join(
    tabla_nulos_original %>% select(Variable, Nulos_orig = Nulos, Pct_orig = Porcentaje),
    by = "Variable"
  ) %>%
  left_join(
    tabla_nulos_sin_dup %>% select(Variable, Nulos_dedup = Nulos, Pct_dedup = Porcentaje),
    by = "Variable"
  ) %>%
  left_join(
    tabla_nulos_consistente %>% select(Variable, Nulos_final = Nulos, Pct_final = Porcentaje),
    by = "Variable"
  ) %>%
  # Se reemplazan los NA resultantes del join por 0
  # (indica que la variable no tenía faltantes en esa etapa)
  mutate(across(where(is.numeric), ~ replace_na(.x, 0)))
```

La Tabla \@ref(tab:tablanulos) presenta la evolución de los datos faltantes en cada etapa del proceso de depuración: dataset original (n = `r nrow(raw_data)`), tras la eliminación de duplicados (n = `r nrow(data_sin_dup)`) y tras la corrección de inconsistencias (n = `r nrow(data_consistente)`).

```{r tablanulos, echo=FALSE}
knitr::kable(
  tabla_comparativa_nulos,
  format = "html",
  caption = "Evolución de datos faltantes por etapa de depuración",
  col.names = c(
    "Variable",
    "NA", "(%)",
    "NA", "(%)",
    "NA", "(%)"
  ),
  align = c("l", rep("r", 6))
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  add_header_above(c(
    " " = 1,
    "Original" = 2,
    "Sin duplicados" = 2,
    "Consistente" = 2
  )) %>%
  column_spec(1, bold = TRUE)
```

Como se observa en la Tabla \@ref(tab:tablanulos), los datos faltantes se concentran exclusivamente en las variables **Income** y **MntWines** a lo largo de las tres etapas. La eliminación de duplicados redujo ligeramente las cantidades absolutas, mientras que la corrección de inconsistencias (remoción de 2 registros con edades no plausibles) no alteró el conteo de faltantes. En el dataset final de trabajo (n = `r nrow(data_consistente)`), **Income** presenta `r tabla_nulos_consistente$Nulos[tabla_nulos_consistente$Variable == "Income"]` valores faltantes (`r tabla_nulos_consistente$Porcentaje[tabla_nulos_consistente$Variable == "Income"]`%) y **MntWines** registra `r tabla_nulos_consistente$Nulos[tabla_nulos_consistente$Variable == "MntWines"]` (`r tabla_nulos_consistente$Porcentaje[tabla_nulos_consistente$Variable == "MntWines"]`%).

Para identificar posibles patrones de co-ausencia, la Figura \@ref(fig:aggrfaltantes) muestra el gráfico de agregación. Las barras de la izquierda indican la proporción de faltantes por variable, mientras que la matriz de la derecha señala si existen registros que carecen de información en múltiples variables simultáneamente.

```{r aggrfaltantes, fig.cap="Gráfico de agregación: Proporción de nulos y combinaciones de co-ausencia.", echo=FALSE, results="hide", fig.width=10, fig.height=8}
VIM::aggr(
  data_consistente,
  col = c("pink", "firebrick"), 
  numbers = TRUE,
  prop = FALSE,
  cex.numbers = 0.8,
  sortVars = TRUE,
  labels = names(data_consistente),
  cex.axis = 0.7,
  las = 2,
  gap = 3,
  combined = FALSE,
  ylab = c("Proporción de datos", "Conteo de faltantes")
)
```

Finalmente, la Figura \@ref(fig:missingmap) presenta el mapa de valores faltantes, que permite observar la distribución espacial de los vacíos a lo largo de todas las observaciones del dataset.

```{r missingmap, fig.width=12, fig.height=6, fig.cap="Mapa de valores faltantes (Matriz de presencia espacial).", echo=FALSE}
vis_miss(data_consistente, sort_miss = TRUE) 
```

La revisión conjunta de las Figuras \@ref(fig:aggrfaltantes) y \@ref(fig:missingmap) confirma que los faltantes aparecen de forma esporádica y dispersa, sin evidencia de patrones estructurados ni bloques sistemáticos de co-ausencia; en particular, la ausencia en *Income* no se encuentra ligada a la ausencia en *MntWines*. Dado que ambas proporciones se sitúan por debajo del umbral del 5% sugerido por la literatura (Little y Rubin, 2002), se espera un impacto limitado sobre los análisis posteriores. No obstante, el tratamiento definitivo de estos datos se determinará tras la ejecución de la prueba de aleatoriedad de Little.

## Tratamiento de datos faltantes

### Evaluación de la aleatoriedad de los datos faltantes

Antes de proceder con la imputación, resulta necesario determinar si los datos faltantes siguen un patrón completamente aleatorio (MCAR) o si, por el contrario, su ausencia está asociada a otras variables del conjunto de datos. Para ello, se aplica el test de Little (1988), incluyendo un conjunto amplio de variables potencialmente relacionadas con la probabilidad de ausencia: ingresos, gasto en vinos, edad, composición del hogar, antigüedad, frecuencia de compras y variables demográficas reconstruidas como factores.

```{r test-mcar, echo=FALSE}
# -------------------------------------------------------------------------
# TEST DE LITTLE PARA EVALUACIÓN DEL MECANISMO MCAR
# -------------------------------------------------------------------------

# Se reconstruyen las variables categóricas originales a partir de las dummies,
# dado que el test requiere variables con estructura factorial para evaluar
# patrones de ausencia condicional

datos_little <- data_consistente %>%
  mutate(
    Education = case_when(
      education_PhD == 1 ~ "PhD",
      education_Master == 1 ~ "Master",
      education_Graduation == 1 ~ "Graduation",
      education_Basic == 1 ~ "Basic",
      education_2n.Cycle == 1 ~ "2n Cycle",
      TRUE ~ NA_character_
    ),
    Marital = case_when(
      marital_Divorced == 1 ~ "Divorced",
      marital_Married == 1 ~ "Married",
      marital_Single == 1 ~ "Single",
      marital_Together == 1 ~ "Together",
      marital_Widow == 1 ~ "Widow",
      TRUE ~ NA_character_
    )
  ) %>%
  select(Income, MntWines, Age, Kidhome, Teenhome, Recency,
         NumWebPurchases, NumStorePurchases, NumCatalogPurchases,
         Education, Marital)

# Conversión a factores para el test
datos_little$Education <- factor(datos_little$Education)
datos_little$Marital <- factor(datos_little$Marital)

# Ejecución del test de Little
test_little <- naniar::mcar_test(datos_little)

# Presentación del resultado
knitr::kable(
  data.frame(
    Estadístico = round(test_little$statistic, 4),
    gl = test_little$df,
    p_valor = round(test_little$p.value, 4)
  ),
  format = "html",
  caption = "Resultado del test de Little para MCAR"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  )
```

La Tabla \@ref(tab:test-mcar) presenta el resultado del test de Little, cuyas hipótesis son:

$$H_0: \text{Los datos faltantes son MCAR (completamente al azar)}$$
$$H_1: \text{Los datos faltantes NO son MCAR}$$

Dado que el p-valor = `r round(test_little$p.value, 4)` resulta inferior al nivel de significancia convencional ($\alpha = 0.05$), se rechaza $H_0$. En consecuencia, los datos no siguen un mecanismo completamente aleatorio (MCAR).

Dado el bajo porcentaje de ausencia (inferior al 5% en ambas variables) y la falta de evidencia estructural que sugiera un mecanismo de tipo MNAR (Missing Not At Random), se seguirá un mecanismo MAR (Missing At Random) para realizar la imputación de los datos. Es decir, se asume que la eliminación de los registros podría inducir sesgo en el estudio, por lo que se opta por imputación múltiple según el marco de Rubin (1987).

### Preparación del conjunto de datos para imputación

Antes de realizar la imputación, es necesario excluir las variables que son el resultado de realizar combinaciones lineales exactas de otras ya presentes en el dataset, esto con el fin de evitar la multicolinealidad perfecta y por lo tanto que resulten matrices singulares en el algoritmo de imputación. Las variables excluidas son:

- **MntTotal**: suma de todos los montos de gasto por categoría.
- **MntRegularProds**: suma de los montos de productos regulares (vinos, frutas, cárnicos, pescado y dulces).
- **AcceptedCmpOverall**: suma de las respuestas a las cinco campañas anteriores.

Estas variables serán recalculadas a partir de sus componentes una vez completada la imputación.

```{r eliminar-redundante, echo=FALSE}
# -------------------------------------------------------------------------
# EXCLUSIÓN DE VARIABLES LINEALMENTE DEPENDIENTES
# -------------------------------------------------------------------------

# Se eliminan variables derivadas para evitar singularidad
# en la matriz de predicción del algoritmo de imputación

datos_imputacion <- data_consistente %>%
  select(-MntRegularProds, -MntTotal, -AcceptedCmpOverall)
```
### Comparación de métodos de imputación

Se evalúan tres métodos de imputación múltiple, cada uno con $m = 5$ imputaciones y 10 iteraciones: PMM (*Predictive Mean Matching*) con regularización ridge, CART (*Classification and Regression Trees*) y regresión ridge. En todos los casos se emplea un subconjunto de variables predictoras seleccionadas por su relevancia teórica y su capacidad explicativa.

```{r imputacion-metodos, echo=FALSE}
# -------------------------------------------------------------------------
# DEFINICIÓN DE VARIABLES PREDICTORAS Y EJECUCIÓN DE IMPUTACIONES
# -------------------------------------------------------------------------

# Subconjunto de variables relevantes para la imputación
vars_predictoras <- c(
  "Age", "Customer_Days", "Recency",
  "NumWebPurchases", "NumCatalogPurchases", "NumStorePurchases",
  "NumWebVisitsMonth", "NumDealsPurchases",
  "Kidhome", "Teenhome",
  "marital_Married", "marital_Single",
  "education_Graduation", "education_Master", "education_PhD",
  "MntMeatProducts", "MntWines", "Income"
)

datos_imp_subset <- datos_imputacion %>%
  select(all_of(vars_predictoras))

# Método 1: PMM con regularización ridge
imp_pmm <- mice(datos_imp_subset, m = 5, method = "pmm",
                ridge = 1e-4, maxit = 10, seed = 42, printFlag = FALSE)

# Método 2: CART (árboles de clasificación y regresión)
imp_cart <- mice(datos_imp_subset, m = 5, method = "cart",
                 maxit = 10, seed = 42, printFlag = FALSE)

# Método 3: Regresión ridge
metodos <- make.method(datos_imp_subset)
metodos["Income"] <- "norm"
metodos["MntWines"] <- "norm"
predictor_matrix <- make.predictorMatrix(datos_imp_subset)
diag(predictor_matrix) <- 0

imp_ridge <- mice(datos_imp_subset, m = 5, method = metodos,
                  predictorMatrix = predictor_matrix,
                  ridge = 1e-3, maxit = 10, seed = 42, printFlag = FALSE)
```

Para seleccionar el método que mejor preserva la estructura de los datos observados, se evalúan tres criterios: estabilidad de las imputaciones (desviación estándar de las medias entre las 5 réplicas), preservación de momentos (comparación de medias y desviaciones estándar con los datos observados) y preservación de correlaciones.

#### Criterio 1: Estabilidad de las imputaciones

La Tabla \@ref(tab:tabla-estabilidad) presenta la desviación estándar de las medias imputadas entre las 5 réplicas para cada método. Un valor menor indica mayor estabilidad, es decir, que las distintas imputaciones producen resultados más consistentes entre sí.

```{r tabla-estabilidad, echo=FALSE}
# -------------------------------------------------------------------------
# FUNCIÓN PARA EXTRAER ESTADÍSTICOS DE IMPUTACIÓN
# -------------------------------------------------------------------------

estadisticos_imputacion <- function(imp, metodo_nombre) {
  completed <- complete(imp, "long")
  
  stats_income <- completed %>%
    group_by(.imp) %>%
    summarise(media_income = mean(Income, na.rm = TRUE),
              sd_income = sd(Income, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media = mean(media_income),
              sd_media = sd(media_income),
              media_sd = mean(sd_income))
  
  stats_wines <- completed %>%
    group_by(.imp) %>%
    summarise(media_wines = mean(MntWines, na.rm = TRUE),
              sd_wines = sd(MntWines, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media_w = mean(media_wines),
              sd_media_w = sd(media_wines),
              media_sd_w = mean(sd_wines))
  
  data.frame(
    Metodo = metodo_nombre,
    Income_media = stats_income$media_media,
    Income_sd = stats_income$media_sd,
    Income_sd_entre = stats_income$sd_media,
    MntWines_media = stats_wines$media_media_w,
    MntWines_sd = stats_wines$media_sd_w,
    MntWines_sd_entre = stats_wines$sd_media_w
  )
}

# Estadísticos observados (casos completos como referencia)
obs_stats <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  summarise(
    Income_media_obs = mean(Income),
    Income_sd_obs = sd(Income),
    MntWines_media_obs = mean(MntWines),
    MntWines_sd_obs = sd(MntWines)
  )

# Compilación de resultados por método
comp_metodos <- bind_rows(
  estadisticos_imputacion(imp_pmm, "PMM"),
  estadisticos_imputacion(imp_cart, "CART"),
  estadisticos_imputacion(imp_ridge, "Ridge")
)

# Cálculo de diferencias relativas respecto a los datos observados
comp_metodos <- comp_metodos %>%
  mutate(
    Income_diff_media = abs(Income_media - obs_stats$Income_media_obs) /
      obs_stats$Income_media_obs * 100,
    Income_diff_sd = abs(Income_sd - obs_stats$Income_sd_obs) /
      obs_stats$Income_sd_obs * 100,
    Wines_diff_media = abs(MntWines_media - obs_stats$MntWines_media_obs) /
      obs_stats$MntWines_media_obs * 100,
    Wines_diff_sd = abs(MntWines_sd - obs_stats$MntWines_sd_obs) /
      obs_stats$MntWines_sd_obs * 100
  )

# -------------------------------------------------------------------------
# TABLA 1: ESTABILIDAD (sd entre réplicas — menor es mejor)
# -------------------------------------------------------------------------

tab_estab <- comp_metodos %>%
  select(Metodo, Income_sd_entre, MntWines_sd_entre)

# Identificar el mejor (mínimo) por columna y colorear en firebrick
tab_estab_fmt <- tab_estab %>%
  mutate(
    Income_sd_entre = cell_spec(
      round(Income_sd_entre, 2), "html",
      color = ifelse(Income_sd_entre == min(Income_sd_entre), "firebrick", "black"),
      bold = ifelse(Income_sd_entre == min(Income_sd_entre), TRUE, FALSE)
    ),
    MntWines_sd_entre = cell_spec(
      round(MntWines_sd_entre, 2), "html",
      color = ifelse(MntWines_sd_entre == min(MntWines_sd_entre), "firebrick", "black"),
      bold = ifelse(MntWines_sd_entre == min(MntWines_sd_entre), TRUE, FALSE)
    )
  )

knitr::kable(
  tab_estab_fmt,
  format = "html",
  escape = FALSE,
  caption = "Estabilidad de las imputaciones: desviación estándar de las medias entre réplicas",
  col.names = c("Método", "SD entre réplicas (Income)", "SD entre réplicas (MntWines)")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

#### Criterio 2: Preservación de momentos

La Tabla \@ref(tab:tabla-momentos) compara las diferencias relativas entre las medias y desviaciones estándar imputadas y las observadas en los datos completos. Un valor menor indica que el método distorsiona menos la distribución original.

```{r tabla-momentos, echo=FALSE}
# -------------------------------------------------------------------------
# TABLA 2: PRESERVACIÓN DE MOMENTOS (diff relativa — menor es mejor)
# -------------------------------------------------------------------------

tab_mom <- comp_metodos %>%
  select(Metodo, Income_diff_media, Income_diff_sd, Wines_diff_media, Wines_diff_sd)

tab_mom_fmt <- tab_mom %>%
  mutate(
    Income_diff_media = cell_spec(
      round(Income_diff_media, 2), "html",
      color = ifelse(Income_diff_media == min(Income_diff_media), "firebrick", "black"),
      bold = ifelse(Income_diff_media == min(Income_diff_media), TRUE, FALSE)
    ),
    Income_diff_sd = cell_spec(
      round(Income_diff_sd, 2), "html",
      color = ifelse(Income_diff_sd == min(Income_diff_sd), "firebrick", "black"),
      bold = ifelse(Income_diff_sd == min(Income_diff_sd), TRUE, FALSE)
    ),
    Wines_diff_media = cell_spec(
      round(Wines_diff_media, 2), "html",
      color = ifelse(Wines_diff_media == min(Wines_diff_media), "firebrick", "black"),
      bold = ifelse(Wines_diff_media == min(Wines_diff_media), TRUE, FALSE)
    ),
    Wines_diff_sd = cell_spec(
      round(Wines_diff_sd, 2), "html",
      color = ifelse(Wines_diff_sd == min(Wines_diff_sd), "firebrick", "black"),
      bold = ifelse(Wines_diff_sd == min(Wines_diff_sd), TRUE, FALSE)
    )
  )

knitr::kable(
  tab_mom_fmt,
  format = "html",
  escape = FALSE,
  caption = "Preservación de momentos: diferencia relativa (%) respecto a datos observados",
  col.names = c("Método", "Δ% Media Income", "Δ% SD Income",
                "Δ% Media MntWines", "Δ% SD MntWines")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

#### Criterio 3: Preservación de correlaciones

La Tabla \@ref(tab:tabla-cor) compara las correlaciones de Pearson entre *Income*, *MntWines* y *Age* para cada método (promedio de las 5 imputaciones) frente a la correlación observada en los datos completos. Se resalta en color el método cuya correlación es más cercana a la observada en cada par de variables.

```{r tabla-cor, echo=FALSE}
# -------------------------------------------------------------------------
# COMPARACIÓN DE CORRELACIONES ENTRE MÉTODOS
# -------------------------------------------------------------------------

# Correlación observada (casos completos)
obs_cor <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  select(Income, MntWines, Age) %>%
  cor(use = "complete.obs")

# Función para calcular correlaciones promedio de las m imputaciones
cor_method <- function(imp) {
  completed <- complete(imp, "long")
  cors <- completed %>%
    group_by(.imp) %>%
    summarise(cor_inc_wine = cor(Income, MntWines, use = "complete.obs"),
              cor_inc_age = cor(Income, Age, use = "complete.obs"),
              cor_wine_age = cor(MntWines, Age, use = "complete.obs")) %>%
    ungroup() %>%
    summarise(across(starts_with("cor"), mean))
  as.numeric(cors)
}

cor_pmm <- cor_method(imp_pmm)
cor_cart <- cor_method(imp_cart)
cor_ridge <- cor_method(imp_ridge)

# Valores observados de referencia
obs_vals <- c(obs_cor["Income","MntWines"], obs_cor["Income","Age"], obs_cor["MntWines","Age"])

# Construir tabla de correlaciones (solo métodos, sin fila observado todavía)
cor_mat <- rbind(cor_pmm, cor_cart, cor_ridge)
metodo_names <- c("PMM", "CART", "Ridge")

# Calcular diferencia absoluta respecto a la observada por cada par
diff_mat <- abs(sweep(cor_mat, 2, obs_vals))

# Identificar el método con menor diferencia por columna
mejor_por_col <- apply(diff_mat, 2, which.min)

# Construir data.frame con formato
tabla_cor_fmt <- data.frame(
  Metodo = c("Observado", metodo_names),
  stringsAsFactors = FALSE
)

for (j in 1:3) {
  col_obs <- round(obs_vals[j], 3)
  col_vals <- round(cor_mat[, j], 3)
  
  # Fila observado sin color especial
  formatted <- c(as.character(col_obs))
  
  # Filas de métodos: colorear el mejor
  for (i in 1:3) {
    if (i == mejor_por_col[j]) {
      formatted <- c(formatted,
        cell_spec(col_vals[i], "html", color = "firebrick", bold = TRUE))
    } else {
      formatted <- c(formatted, as.character(col_vals[i]))
    }
  }
  
  tabla_cor_fmt[[paste0("V", j)]] <- formatted
}

names(tabla_cor_fmt)[2:4] <- c("Income ~ MntWines", "Income ~ Age", "MntWines ~ Age")

knitr::kable(
  tabla_cor_fmt,
  format = "html",
  escape = FALSE,
  caption = "Correlaciones promedio (5 imputaciones) comparadas con las observadas"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(1, background = "#f0f0f0", italic = TRUE)
```

<!-- ================================================================== -->
<!-- JUSTIFICACIÓN PENDIENTE: la redacción interpretativa de estas      -->
<!-- tablas se completará en una etapa posterior.                        -->
<!-- ================================================================== -->

Con base en los resultados de las Tablas \@ref(tab:tabla-estabilidad), \@ref(tab:tabla-momentos) y \@ref(tab:tabla-cor), se selecciona **CART** como método final de imputación.

### Verificación de estabilidad y construcción del dataset imputado

Para confirmar que las cinco imputaciones generadas por CART producen resultados consistentes, la Tabla \@ref(tab:consistencia-imputaciones) presenta las medias de *Income* y *MntWines* en cada una de las réplicas.

```{r consistencia-imputaciones, echo=FALSE}
# -------------------------------------------------------------------------
# VERIFICACIÓN DE CONSISTENCIA ENTRE IMPUTACIONES (CART)
# -------------------------------------------------------------------------

completed_cart <- complete(imp_cart, "long")

medias_por_imp <- completed_cart %>%
  group_by(.imp) %>%
  summarise(
    Media_Income = mean(Income),
    Media_MntWines = mean(MntWines)
  )

knitr::kable(
  medias_por_imp,
  digits = 2,
  format = "html",
  col.names = c("Imputación", "Media Income", "Media MntWines"),
  caption = "Medias por imputación (CART): verificación de estabilidad"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

La baja variabilidad entre imputaciones confirma la estabilidad del método. Se utiliza la primera imputación para la construcción del dataset final, sobre el cual se recalculan las variables derivadas previamente excluidas.

```{r construccion-dataset-final, echo=FALSE}
# -------------------------------------------------------------------------
# CONSTRUCCIÓN DEL DATASET FINAL IMPUTADO (CART)
# -------------------------------------------------------------------------

# Se extrae la primera imputación del objeto CART
datos_final_subset <- complete(imp_cart, 1)

# Se reemplazan las variables imputadas en el dataset completo
datos_final <- datos_imputacion
datos_final$Income <- datos_final_subset$Income
datos_final$MntWines <- datos_final_subset$MntWines

# Recálculo de variables derivadas con las fórmulas verificadas
# en la sección de corrección de inconsistencias
datos_final <- datos_final %>%
  mutate(
    MntTotal = MntWines + MntFruits + MntMeatProducts +
               MntFishProducts + MntSweetProducts + MntGoldProds,
    MntRegularProds = MntWines + MntFruits + MntMeatProducts +
                      MntFishProducts + MntSweetProducts,
    AcceptedCmpOverall = AcceptedCmp1 + AcceptedCmp2 + AcceptedCmp3 +
                         AcceptedCmp4 + AcceptedCmp5
  )
```

### Comparación de estadísticos antes y después de la imputación

La Tabla \@ref(tab:antes-despues) presenta los principales estadísticos descriptivos de *Income* y *MntWines* calculados antes de la imputación (sobre los datos observados, excluyendo NA) y después de la imputación (sobre el dataset completo). Esta comparación permite verificar que el método CART no introdujo distorsiones relevantes en la estructura de los datos.

<div style="overflow-x: auto; width: 100%;">
```{r antes-despues, echo=FALSE}
# -------------------------------------------------------------------------
# TABLA COMPARATIVA: ESTADÍSTICOS ANTES Y DESPUÉS DE IMPUTACIÓN
# -------------------------------------------------------------------------

# Función para calcular estadísticos descriptivos de una variable
calc_stats <- function(x, etiqueta) {
  data.frame(
    Etapa = etiqueta,
    Min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    Mediana = median(x, na.rm = TRUE),
    Media = round(mean(x, na.rm = TRUE), 2),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    Max = max(x, na.rm = TRUE),
    SD = round(sd(x, na.rm = TRUE), 2),
    n = sum(!is.na(x)),
    row.names = NULL
  )
}

# Income: antes y después
stats_income_antes <- calc_stats(data_consistente$Income, "Antes (observados)")
stats_income_despues <- calc_stats(datos_final$Income, "Después (imputado)")
tab_income <- bind_rows(stats_income_antes, stats_income_despues)

# MntWines: antes y después
stats_wines_antes <- calc_stats(data_consistente$MntWines, "Antes (observados)")
stats_wines_despues <- calc_stats(datos_final$MntWines, "Después (imputado)")
tab_wines <- bind_rows(stats_wines_antes, stats_wines_despues)

# Tabla combinada
tab_ad <- bind_rows(
  tab_income %>% mutate(Variable = "Income"),
  tab_wines %>% mutate(Variable = "MntWines")
) %>%
  select(Variable, Etapa, n, Min, Q1, Mediana, Media, Q3, Max, SD)

knitr::kable(
  tab_ad,
  format = "html",
  caption = "Estadísticos descriptivos de Income y MntWines antes y después de la imputación",
  col.names = c("Variable", "Etapa", "n", "Mín", "Q1", "Mediana",
                "Media", "Q3", "Máx", "SD"),
  align = c("l", "l", rep("r", 8))
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE) %>%
  collapse_rows(columns = 1, valign = "middle")
```
</div>


También se puede confirmar que la imputación no haya distorsionado las distribuciones originales revisando la Figura \@ref(fig:densidad-compa) que también compara las curvas de densidad de *Income* y *MntWines* antes y después de la imputación.

```{r densidad-compa, echo=FALSE, fig.cap="Densidades originales vs. imputadas para Income y MntWines.", fig.width=12, fig.height=5}
# -------------------------------------------------------------------------
# COMPARACIÓN DE DENSIDADES PRE Y POST IMPUTACIÓN
# -------------------------------------------------------------------------

# Se desactiva temporalmente ggthemr para controlar la paleta de colores
ggthemr_reset()

p1 <- ggplot() +
  geom_density(data = data_consistente,
               aes(x = Income, color = "Original (con NA)"),
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final,
               aes(x = Income, color = "Imputado"),
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original (con NA)" = "#5A6E3A", "Imputado" = "firebrick")
  ) +
  labs(title = "Income: Original vs. Imputado",
       x = "Ingreso anual", y = "Densidad") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "bottom")

p2 <- ggplot() +
  geom_density(data = data_consistente,
               aes(x = MntWines, color = "Original (con NA)"),
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final,
               aes(x = MntWines, color = "Imputado"),
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original (con NA)" = "#5A6E3A", "Imputado" = "firebrick")
  ) +
  labs(title = "MntWines: Original vs. Imputado",
       x = "Monto en vinos", y = "Densidad") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "bottom")

grid.arrange(p1, p2, ncol = 2)

# Se restaura el tema global para los chunks posteriores
ggthemr("dust", layout = "clean")
```

Las curvas muestran una superposición prácticamente completa, sin distorsiones visibles en la forma ni en la localización de las distribuciones. 

```{r exportacion-datos-final, include=FALSE}
# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET FINAL IMPUTADO
# -------------------------------------------------------------------------
write.csv(
  datos_final,
  file = "data_limpia/data_final_imputada.csv",
  row.names = FALSE
)
```


