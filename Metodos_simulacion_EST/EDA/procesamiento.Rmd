# Procesamiento

-   Vamos Leer el archivo de datos *data_actividad1*

```{r, results = "hide"}
data_act1 <- read_xlsx("data/data_actividad1.xlsx")
```

## Resumen estadístico

La Tabla \@ref(tab:resumenestadistico) presenta un resumen de las principales estadísticas descriptivas para las variables numéricas del dataset, incluyendo medidas de tendencia central, dispersión y el número de datos faltantes por variable.

```{r resumenestadistico}


# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR ESTADÍSTICAS DESCRIPTIVAS
# -------------------------------------------------------------------------

# Se define una función que calcula medidas de tendencia central y dispersión
# para una variable numérica específica.
# La función recibe:
# - variable: vector numérico
# - nombre_variable: nombre de la variable (como texto)

resumen_estadistico <- function(variable, nombre_variable){
  tibble(
    Variable = nombre_variable, 
    # Nombre de la variable analizada
    
    Min = min(variable, na.rm = TRUE),
    # Valor mínimo observado (excluyendo NA)
    
    Max = max(variable, na.rm = TRUE),
    # Valor máximo observado (excluyendo NA)
    
    Median = median(variable, na.rm = TRUE),
    # Mediana (medida robusta de tendencia central)
    
    Media = round(mean(variable, na.rm = TRUE), 2),
    # Media aritmética (redondeada a 2 decimales)
    
    std = round(sd(variable, na.rm = TRUE), 2),
    # Desviación estándar (medida de dispersión)
    
    Q_1 = quantile(variable, 0.25, na.rm = TRUE),
    # Primer cuartil (25%)
    
    Q_3 = quantile(variable, 0.75, na.rm = TRUE)
    # Tercer cuartil (75%)
  )
}

# -------------------------------------------------------------------------
# IDENTIFICAR VARIABLES NUMÉRICAS DEL DATASET
# -------------------------------------------------------------------------

columnas_numericas <- names(data_act1)[sapply(data_act1, is.numeric)]
# sapply(..., is.numeric) identifica qué columnas son numéricas
# names(...) devuelve los nombres de dichas columnas

# -------------------------------------------------------------------------
# APLICAR FUNCIÓN A CADA VARIABLE NUMÉRICA
# -------------------------------------------------------------------------

estadisticas <- bind_rows(
  lapply(columnas_numericas, function(col) {
    resumen_estadistico(data_act1[[col]], col)
  })
)
# lapply recorre cada columna numérica
# bind_rows une todos los resultados en una sola tabla

# -------------------------------------------------------------------------
# CÁLCULO DE DATOS FALTANTES
# -------------------------------------------------------------------------

# colSums(is.na()) cuenta el número de NA por variable
# Se convierte en data frame y se agrega el nombre de la variable como columna
faltantes <- colSums(is.na(data_act1)) %>% 
  as.data.frame() %>%
  tibble::rownames_to_column("Variable")



# Se renombran las columnas para mayor claridad
colnames(faltantes) <- c("Variable", "NA's")


# -------------------------------------------------------------------------
# UNIÓN DE ESTADÍSTICAS Y DATOS FALTANTES
# -------------------------------------------------------------------------

tabla_completa <- left_join(estadisticas, faltantes, by = "Variable")
# left_join combina ambas tablas usando el nombre de la variable como clave

# -------------------------------------------------------------------------
# PRESENTACIÓN DE LA TABLA
# -------------------------------------------------------------------------

kable(tabla_completa, format = "html", 
      caption = "Estadísticas descriptivas y datos faltantes") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)

# Se genera una tabla formateada con:
# - Medidas descriptivas
# - Cantidad de valores faltantes
```

Desde esta primera visualización emergen aspectos que requieren atención en etapas posteriores: alta dispersión en *Income* y en las variables de gasto (*Mnt*), con diferencias entre media y mediana que sugieren asimetrías positivas; valores faltantes exclusivamente en *Income* y *MntWines*; un valor mínimo negativo en *MntRegularProds* que podría indicar un error de registro; un máximo de 100 en *marital_Divorced* incompatible con su naturaleza binaria; una mediana de 0 en *AcceptedCmpOverall*, indicando que la mayoría de los clientes no aceptaron ninguna de las 5 campañas previas; y valores máximos superiores a 1000 u.m. en *MntWines* y *MntMeatProducts*, señalando categorías con alta concentración de gasto en determinados clientes.

## Identificación y eliminación de duplicados

En esta etapa se procede a verificar la existencia de registros duplicados en el dataset, con el objetivo de garantizar que cada fila represente una observación única.

```{r tabladuplicados }
# Identificamos los duplicados
total_datos <- nrow(data_act1)
duplicados <- duplicated(data_act1)
total_duplicados <- sum(duplicados)

# Eliminar duplicados
data_sin_dup <- data_act1[!duplicados, ]

# Tabla con información de duplicados en formato vertical
resumen_duplicados <- data.frame(
  Concepto = c(
    "Total de datos original",
    "Total de duplicados",
    "Porcentaje de duplicados (%)",
    "Total de datos sin duplicados"
  ),
  Valor = c(
    total_datos,
    total_duplicados,
    paste(round(total_duplicados/nrow(data_act1)  * 100, 2), "%"),
    nrow(data_sin_dup)
  )
)
# danmos formato a la tabla de reporte de duplicados
knitr::kable(
  resumen_duplicados,
  caption = "Detección y eliminación de duplicados",
  label = "tabladuplicados",
  col.names = c("Concepto", "Valor"),
  align = c("l", "l")
)

```

```{r eliminacion_duplicados, include=FALSE}

# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET DEPURADO
# -------------------------------------------------------------------------
write.csv(
  data_sin_dup,
  file = "data_limpia/data_sin_duplicados.csv",
  row.names = FALSE
)
# Se exporta el nuevo dataset limpio en formato CSV
```

La Tabla \@ref(tab:tabladuplicados) muestra que inicialmente se contaba con 2220 observaciones, de las cuales 179 correspondían a registros duplicados representando el 8.06 % del total de registros. Tras su eliminación, el conjunto de datos quedó conformado por 2041 registros únicos.

```{r carga_dataset_limpio}
data_act1 <- read.csv("data_limpia/data_sin_duplicados.csv")
# Se reemplaza el dataset original por la versión depurada
```

Veamos el resumen estadístico del nuevo dataset en la tabla \@ref(tab:resumenpostlimpieza)

```{r resumenpostlimpieza}
# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR ESTADÍSTICAS DESCRIPTIVAS
# -------------------------------------------------------------------------

resumen_estadistico <- function(variable, nombre_variable){
  tibble(
    Variable = nombre_variable,
    Min = min(variable, na.rm = TRUE),
    Max = max(variable, na.rm = TRUE),
    Median = median(variable, na.rm = TRUE),
    Media = round(mean(variable, na.rm = TRUE), 2),
    std = round(sd(variable, na.rm = TRUE), 2),
    Q_1 = quantile(variable, 0.25, na.rm = TRUE),
    Q_3 = quantile(variable, 0.75, na.rm = TRUE)
  )
}

# Identificación de columnas numéricas
columnas_numericas <- names(data_act1)[sapply(data_act1, is.numeric)]

# Aplicación de la función a cada variable numérica
estadisticas <- bind_rows(
  lapply(columnas_numericas, function(col) {
    resumen_estadistico(data_act1[[col]], col)
  })
)

# Cálculo de valores faltantes
faltantes <- colSums(is.na(data_act1)) %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Variable")

colnames(faltantes) <- c("Variable", "NA's")

# Unión de estadísticas descriptivas y faltantes
tabla_completa <- left_join(estadisticas, faltantes, by = "Variable")

# Presentación de la tabla
kable(tabla_completa, format = "html",
      caption = "Estadísticas descriptivas y datos faltantes (post eliminación de duplicados)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"),
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

Al comparar las Tablas \@ref(tab:resumenestadistico) y \@ref(tab:resumenpostlimpieza), no se observan cambios significativos tras la eliminación de duplicados: las ligeras variaciones en medidas de tendencia central no alteran los patrones previamente identificados, lo que indica que los registros duplicados se encontraban distribuidos de manera homogénea en el dataset.

## Errores e inconsistencias

### Identificación de valores atípicos para variables cualitativas binarias

A continuación, se analizan las variables cualitativas binarias con el objetivo de detectar posibles inconsistencias, categorías inesperadas o desbalances extremos en las frecuencias.

```{r seleccion_binarias}
# -------------------------------------------------------------------------
# SELECCIÓN DE VARIABLES CUALITATIVAS BINARIAS
# -------------------------------------------------------------------------

variables_binarias <- data_act1 %>%
  
# Se seleccionan explícitamente las variables binarias del dataset.
# Estas corresponden a indicadores de respuesta a campañas,
# nivel educativo y estado civil.
  
  dplyr::select(AcceptedCmp1,AcceptedCmp2,AcceptedCmp3,AcceptedCmp4,AcceptedCmp5, Response, Complain,
    education_2n.Cycle,education_Basic,education_Graduation,
    education_Master,education_PhD,
    marital_Divorced,marital_Married,marital_Single,
    marital_Together, marital_Widow)


```

Posteriormente, se construyen diagramas de barras para visualizar la distribución de frecuencias de cada variable binaria y realizar un análisis gráfico que permita identificar las variables que aporten información relevante y las que requieran un tratamiento especial.

```{r barplotbinarias, fig.cap="Distribución de variables binarias", fig.height=40, fig.width=14}

# -------------------------------------------------------------------------
# VISUALIZACIÓN DE FRECUENCIAS PARA VARIABLES BINARIAS
# -------------------------------------------------------------------------

# Vector con los nombres de las variables binarias
vars_binarias <- c("AcceptedCmp1", "AcceptedCmp2","AcceptedCmp3","AcceptedCmp4",
                   "AcceptedCmp5","Response","Complain","marital_Single",
                   "marital_Together", "marital_Married","marital_Divorced",
                   "marital_Widow", "education_Basic", "education_2n.Cycle",
                   "education_Graduation", "education_Master", "education_PhD")


# Se genera una lista de gráficos, uno por cada variable
lista_graficos <- lapply(seq_along(vars_binarias), function(i) {
  var <- vars_binarias[i]
  
 # Cálculo de frecuencias absolutas
  tabla_freq <- data_act1 %>%
    count(!!sym(var)) %>%
    rename(Categoria = 1, Frecuencia = n) %>%
    mutate(Categoria = factor(Categoria, levels = c(0, 1), labels = c("No", "Sí")))
  
  # Construcción del gráfico de barras
  ggplot(tabla_freq, aes(x = Categoria, y = Frecuencia, fill = Categoria)) +
    geom_bar(stat = "identity", alpha = 1, color = "grey20", linewidth = 0.5, show.legend = FALSE) +
    geom_text(aes(label = Frecuencia), vjust = -0.5, size = 4, fontface = "bold") +
    scale_fill_manual(values = c("No" = "pink", "Sí" = "#BAC095")) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 10, face = "bold"),
      plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
      panel.grid.major.x = element_blank()
    ) +
    labs(
      title = var,
      x = "",
      y = "Frecuencia"
    ) +
    ylim(0, max(tabla_freq$Frecuencia) * 1.15)
})

# Organización de los gráficos en una cuadrícula de dos columnas
do.call(grid.arrange, c(lista_graficos, ncol = 2))
```

El análisis gráfico de la Figura \@ref(fig:barplotbinarias) permite identificar varios patrones relevantes. La respuesta a las campañas 1 a 5 fue considerablemente baja (entre 27 y 158 aceptaciones), mientras que la campaña piloto alcanzó 314 respuestas positivas, lo que sugiere una mejora en la estrategia o segmentación. La variable *Complain* registra únicamente 19 quejas, evidenciando baja proporción de inconformidades.

Respecto al estado civil, la mayoría de los clientes se encuentran casados o en unión libre. Se detecta que 6 registros en *marital_Divorced* presentan el valor 100, lo cual constituye una inconsistencia que debe corregirse dado su dominio binario. En cuanto al nivel educativo, aproximadamente la mitad de los clientes (1023) cuentan con título universitario.

### Identificación de valores atípicos para variables discretas

En esta sección se identifican posibles valores atípicos en las variables cuantitativas discretas del conjunto de datos. Para ello, se emplea el criterio basado en el rango intercuartílico (IQR).

```{r atipicasdiscretas, }
# Función para detectar valores atípicos mediante el criterio del IQR
# Recibe como argumento un vector numérico (var)

detectar_atipicos <- function(var){
  # Calcula los cuartiles Q1 (25%) y Q3 (75%) ignorando valores NA
  Q1 <- quantile(var,0.25,na.rm = TRUE)
  Q3 <- quantile(var,0.75,na.rm = TRUE)
  # Determina el rango intercuartílico (IQR = Q3 - Q1)
  IQR <- Q3-Q1
  # Retorna las posiciones (índices) de los valores que se encuentran por debajo de Q1 - 1.5*IQR o por encima de Q3 + 1.5*IQR
  which(var < (Q1-1.5*IQR) | var > (Q3+1.5*IQR))
}

# Selección de variables cuantitativas discretas desde el dataset principal
variables_discretas <- data_act1 %>%
  
# Se extraen variables relacionadas con composición del hogar, historial de campañas y frecuencia de compras en distintos canales
dplyr::select(Kidhome, Teenhome, Age, Recency, Customer_Days,   AcceptedCmpOverall, NumDealsPurchases, NumCatalogPurchases, NumStorePurchases,  NumWebPurchases, NumWebVisitsMonth)


# Identificación de valores atípicos por variable
# lapply aplica la función detectar_atipicos a cada columna
# El resultado es una lista donde cada elemento contiene las posiciones de los valores atípicos por variable

atipicos_d <- lapply(variables_discretas, detectar_atipicos)
```

La Tabla \@ref(tab:tablaatipicosdiscretos) indica el número total de valores atípicos encontrados en cada variable. Esto permite evaluar rápidamente cuáles presentan mayor concentración de observaciones extremas.

```{r tablaatipicosdiscretos, }
# Construcción de tabla resumen de valores atípicos

tabla_atipicos_d <- data.frame(
  # names(atipicos_d) extrae los nombres de las variables
  variable = names(atipicos_d),
  # sapply(..., length) calcula cuántos atípicos tiene cada variable
  total_atipicos_d = sapply(atipicos_d, length),
  stringsAsFactors = FALSE
  # Se crea un data.frame con el total por variable
)


# Creación de tabla con formato HTML usando kable
# Se agrega título y estilo visual para mejorar la presentación del informe
kable(tabla_atipicos_d, format = "html", 
      caption = "Tabla de valores atípicos por variable") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

La Tabla \@ref(tab:tablaatipicosdiscretos) muestra que *Age* presenta únicamente 2 observaciones extremas (≈0.1%), mientras que *NumWebPurchases* y *NumWebVisitsMonth* registran menos de 10 cada una (<0.5%). Las variables *NumDealsPurchases* (74 atípicos, ≈3.6%) y *NumCatalogPurchases* (19, ≈0.9%) presentan concentraciones moderadas. El caso más llamativo es *AcceptedCmpOverall*, con 431 valores atípicos (≈21.1%), consecuencia de la fuerte concentración en el valor 0.

Con el fin de emitir un juicio más preciso sobre estos casos, se realiza a continuación una inspección visual mediante diagramas de caja (boxplots) para cada variable discreta.

```{r boxplotdiscreta, fig.cap="Distribución de variables discretas", fig.height=20}
vars <- names(variables_discretas)

plots_list <- lapply(vars, function(var) {
  ggplot(data_act1, aes(y = .data[[var]])) +
    geom_boxplot(fill = "pink", alpha = 0.7,
                 median.colour = "firebrick") +
    labs(
      title = paste("Boxplot de", var),
      y = var
    ) +
    theme_minimal()
})

wrap_plots(plots_list, ncol = 2)
```

La Figura \@ref(fig:boxplotdiscreta) complementa el análisis del IQR. En *Age*, los valores extremos corresponden a edades superiores a 200 años, registros biológicamente imposibles que constituyen errores evidentes y requieren depuración. En *AcceptedCmpOverall*, no se aprecia una caja definida sino únicamente la mediana en 0 con puntos aislados en 1, 2, 3 y 4, confirmando que la aceptación de campañas es un comportamiento poco frecuente. Un patrón similar se observa en *NumDealsPurchases* y *NumCatalogPurchases*, con distribuciones concentradas en valores bajos y algunos valores superiores aislados.

En conjunto, salvo en *Age*, los valores atípicos responden a distribuciones discretas con alta concentración en cero y marcada asimetría positiva.

### Identificación de valores atípicos para variables continuas

Finalmente, se analiza la presencia de valores atípicos en las variables cuantitativas continuas, principalmente asociadas a ingresos y montos de gasto por categoría de producto.

```{r tablaatipicoscontinuas}

# Selección de variables cuantitativas continuas desde el dataset principal
# Se incluyen variables de ingreso (Income) y montos de gasto por categoría
# así como variables agregadas de gasto total y gasto regular

variables_continuas <- data_act1 %>%
  dplyr::select(Income, MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds,  MntTotal, MntRegularProds)

# Identificación de valores atípicos por variable continua
# lapply aplica la función detectar_atipicos a cada columna seleccionada. El resultado es una lista con los índices de observaciones atípicas


atipicos_c <- lapply(variables_continuas, detectar_atipicos)

# Construcción de tabla resumen de valores atípicos



tabla_atipicos_c <- data.frame(
  # names(atipicos_c) extrae los nombres de las variables
  variable = names(atipicos_c),
  # sapply(..., length) calcula la cantidad de atípicos por variable
  total_atipicos_c = sapply(atipicos_c, length),
  # Se organiza la información en un data.frame para su presentación
  stringsAsFactors = FALSE
)

# Creación de tabla con formato HTML usando kable
# Se agrega título y formato visual para su integración en el informe
kable(tabla_atipicos_c, format = "html", 
      caption = "Tabla de valores atípicos por variable") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), 
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE)
```

Si bien en la Tabla \@ref(tab:resumenestadistico) se anticipaba que *MntWines* y *MntMeatProducts* serían las variables con mayor presencia de atípicos por sus elevados valores máximos, la Tabla \@ref(tab:tablaatipicoscontinuas) muestra un resultado diferente: *MntFruits*, *MntFishProducts* y *MntSweetProducts* registran más de 200 valores atípicos cada una. Esto se explica por su fuerte concentración en valores bajos y su marcada asimetría, que provoca que consumos relativamente moderados excedan el rango intercuartílico. *MntMeatProducts* presenta 170 atípicos, coherente con su alta dispersión. La única variable continua sin datos atípicos es *Income*.

Con el fin de emitir un juicio más preciso sobre estos casos, se realiza a continuación una inspección visual mediante diagramas de caja (boxplots) para cada variable continua.

```{r boxplotcontinuas, fig.cap="Distribución de variables continuas", fig.height=20}
vars <- names(variables_continuas)

plots_list <- lapply(vars, function(var) {
  ggplot(data_act1, aes(y = .data[[var]])) +
    geom_boxplot(fill = "pink", alpha = 0.7,
                 median.colour = "firebrick") +
    labs(
      title = paste("Boxplot de", var),
      y = var
    ) +
    theme_minimal()
})

wrap_plots(plots_list, ncol = 2)
```

En la Figura \@ref(fig:boxplotcontinuas), todas las cajas de las variables *Mnt* se concentran en la parte inferior, reflejando una fuerte acumulación en niveles bajos de gasto con colas superiores extendidas. La excepción parcial es *MntRegularProds*, cuyo eje se extiende hacia valores negativos (previamente detectados en la Tabla \@ref(tab:resumenestadistico)). Esta configuración indica que una proporción importante de clientes presenta gasto nulo o reducido en cada categoría, y que los valores atípicos no representan necesariamente anomalías, sino un subconjunto de consumidores intensivos relevante para la segmentación.

## Solución de inconsistencias

Con base en los hallazgos obtenidos en el análisis descriptivo y en la detección de valores atípicos, se procede a identificar formalmente registros inconsistentes en variables específicas mendiante la tabla \@ref(tab:tabinconsistencia).

```{r tabinconsistencia}
inconsistencias <- tibble(
  Variable = c("MntRegularProds", "Age", "marital_Divorced"),
  Registros_invalidos = c(
    sum(data_act1$MntRegularProds < 0, na.rm = TRUE),
    sum(data_act1$Age <= 0 | data_act1$Age > 110, na.rm = TRUE),
    sum(!data_act1$marital_Divorced %in% c(0,1), na.rm = TRUE)
  ),
  Valores_invalidos = c(
    paste(unique(data_act1$MntRegularProds[
      data_act1$MntRegularProds < 0
    ]), collapse = ", "),
    
    paste(unique(data_act1$Age[
      data_act1$Age <= 0 | data_act1$Age > 110
    ]), collapse = ", "),
    
    paste(unique(data_act1$marital_Divorced[
      !data_act1$marital_Divorced %in% c(0,1)
    ]), collapse = ", ")
  )
)

knitr::kable(
  inconsistencias,
  caption = "Cantidad y valores de registros inconsistentes por variable",
  align = c("l", "c", "l")
)

```

### Inspección y depuración de la variable *marital_Divorced*

Dado que se detectaron valores fuera del dominio esperado (0 y 1) en *marital_Divorced*, se realiza una inspección detallada de sus categorías en la Figura \@ref(fig:divorcedF).

```{r divorcedF, fig.cap="Distribución de Estado de Divorcio"}
# Crear tabla de frecuencias y ordenar manualmente
data_act1_temp <- data_act1 %>%
  mutate(Estado_Divorcio = case_when(
    marital_Divorced == 0 ~ "No Divorciado",
    marital_Divorced == 1 ~ "Divorciado",
    marital_Divorced == 100 ~ "Error (100)",
    TRUE ~ "Otro"
  )) %>%
  count(Estado_Divorcio) %>%
  arrange(desc(n)) %>%
  mutate(Estado_Divorcio = factor(Estado_Divorcio, levels = Estado_Divorcio))

# Gráfico
ggplot(data_act1_temp, aes(x = Estado_Divorcio, y = n)) +
  geom_col(fill = "pink", color = "black", width = 0.3) +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(title = "Distribución de Estado de Divorcio",
       x = "Estado",
       y = "Frecuencia") +
  theme_minimal()
```

Posteriormente, se construye la Tabla \@ref(tab:divorcetab) que permiten visualizar la distribución de los valores en las variables relacionadas al estado civil sólo en los registros que contienen el valor 100 como posible error de codificación.

```{r divorcetab}
# Ver registros con valor 100
auditar_estado_civil <- function(data) {
  
  vars_marital <- c(
    "marital_Single",
    "marital_Together",
    "marital_Married",
    "marital_Divorced",
    "marital_Widow"
  )
  
  resultado <- data %>%
    dplyr::mutate(
      suma_marital = rowSums(dplyr::select(., dplyr::all_of(vars_marital)), 
                             na.rm = TRUE)
    ) %>%
    dplyr::filter(suma_marital >= 100) %>%
    dplyr::select(dplyr::all_of(vars_marital), )
  
  return(resultado)
  }

tabla_marital_inconsistente <- auditar_estado_civil(data_act1)

knitr::kable(
  tabla_marital_inconsistente,
  caption = "Registros con valor anómalo en variables de estado civil",
  align = "c",
  full_width = TRUE
)
```

Dado que las variables dummy de estado civil solo admiten valores 0 o 1 y cada cliente debe tomar el valor 1 en exactamente una de ellas, el valor 100 en *marital_Divorced* constituye un error de digitación. Se procede a reemplazarlo por 1, preservando la integridad del sistema de variables dummy.

```{r correccion-marital-divorced}
# Corrección del error de codificación en marital_Divorced
# Se reemplaza el valor 100 por 1

data_act1 <- data_act1 %>%
  mutate(
    marital_Divorced = ifelse(marital_Divorced == 100, 1, marital_Divorced)
  )
```

La corrección incrementa la proporción de clientes divorciados en apenas 0.29 puntos porcentuales (de 10.24% a 10.53%), una variación mínima que preserva la estructura original de la variable sin introducir distorsiones.

### Inspección y depuración de la variable *Age*

En la revisión preliminar (ver Tabla \@ref(tab:tabinconsistencia)), se identificaron 2 registros con valor 240 en la variable *Age*, valor que excede claramente el rango biológicamente plausible para la edad humana.

```{r inspedades, fig.cap = "Distribución de la variable Edad con histograma y curva de densidad"}
dist_edades <- ggplot(data_act1, aes(x = Age)) +
    geom_histogram(aes(y = after_stat(density)), bins = 40,
                   fill = "pink", color = "black", alpha = 0.7) +
    geom_density(color = "firebrick", linewidth = 0.5) +
    labs(title = "Distribución de Edades",
         x = "Edades",
         y = "Densidad") +
    theme_minimal()

dist_edades
```

Como se observa en la Figura \@ref(fig:inspedades) y en el boxplot de la Figura \@ref(fig:boxplotdiscreta), la distribución de edades se concentra entre los 25 y 75 años sin indicios de otros valores extremos salvo los dos registros con valor 240. Aunque podría tratarse de un error de digitación (e.g., 24), realizar dicha sustitución introduciría un supuesto no verificable. Dado que se trata de solo 2 registros (≈0.098% de 2041), se opta por eliminarlos, quedando el dataset con 2039 observaciones.


```{r correccion-age, include=FALSE }
# Eliminación de registros con edades no plausibles

data_consistente <- data_act1 %>%
  filter(Age > 0 & Age <= 110)

# Verificación del nuevo tamaño del dataset
nrow(data_consistente)
```



### Inspección y depuración de la variable *MntRegularProds*

En la Tabla \@ref(tab:tabinconsistencia) se identificaron tres valores negativos en la variable *MntRegularProds* (-151, -166 y -283). Dado que esta variable representa un monto de gasto, los valores negativos no resultan coherentes bajo una interpretación directa del indicador.

La Figura \@ref(fig:distmntregularantes) muestra la distribución de la variable. Visualmente, los valores negativos aparecen como observaciones aisladas en el extremo izquierdo de la distribución.

```{r distmntregularantes, fig.cap="Distribución original de MntRegularProds con histograma y curva de densidad"}
ggplot(data_act1, aes(x = MntRegularProds)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50,
                 fill = "pink", color = "black", alpha = 0.7) +
  geom_density(color = "firebrick", linewidth = 1) +
  labs(title = "Distribución de Monto en Productos Regulares",
       x = "Monto (MntRegularProds)",
       y = "Densidad") +
  theme_minimal()
```

Sin documentación que respalde devoluciones o ajustes contables, se planteó la hipótesis de que *MntRegularProds* corresponde a la suma de los productos regulares (vinos, frutas, carne, pescado y dulces). Para verificarlo, se calcularon dos métodos (suma directa y monto total menos oro) sobre los tres registros inconsistentes, comparando sus resultados.

```{r tablaverificacionmntregular}
# -------------------------------------------------------------------------
# TABLA COMPARATIVA DE MÉTODOS DE CÁLCULO
# -------------------------------------------------------------------------

verificacion_mnt <- data_act1 %>%
  filter(MntRegularProds < 0) %>%
  mutate(
    Metodo_Total_menos_Oro = (MntWines + MntFruits + MntMeatProducts +
                              MntFishProducts + MntSweetProducts + MntGoldProds) -
                              MntGoldProds,
    Metodo_Suma_Regular = MntWines + MntFruits + MntMeatProducts +
                          MntFishProducts + MntSweetProducts,
    Diferencia = Metodo_Total_menos_Oro - Metodo_Suma_Regular
  ) %>%
  select(Metodo_Total_menos_Oro, Metodo_Suma_Regular, Diferencia)

knitr::kable(
  verificacion_mnt,
  caption = "Comparación de métodos de cálculo para registros con MntRegularProds negativo",
  align = "c"
)
```


La Tabla \@ref(tab:tablaverificacionmntregular) muestra que la columna Diferencia es 0 en los tres registros, validando la hipótesis. En consecuencia, se recalcularon los valores inconsistentes preservando los registros originales.

```{r correccion-mntregular}
# -------------------------------------------------------------------------
# OPCIÓN 1: RECÁLCULO DE LOS VALORES
# -------------------------------------------------------------------------

data_consistente <- data_consistente %>%
  mutate(
    MntRegularProds = ifelse(
      MntRegularProds < 0,
      MntWines + MntFruits + MntMeatProducts +
      MntFishProducts + MntSweetProducts,
      MntRegularProds
    )
  )
```


Dado que únicamente tres observaciones (3/2039) fueron modificadas, se espera que el impacto distributivo sea mínimo. A continuación, se presentan las comparaciones gráficas del dataset original y el dataset corregido .


```{r comparacionmntregularfinal, fig.cap="Distribución comparativa de MntRegularProds antes (rosa) y después (verde) de la corrección"}

# Unificar datasets

datos_comparacion <- bind_rows(
  data_act1 %>% mutate(Dataset = "Antes"),
  data_consistente %>% mutate(Dataset = "Después")
)

# Gráfico combinado: histogramas + densidades

dist_mntregular <- ggplot(datos_comparacion, aes(x = MntRegularProds)) +
  
  # Histogramas con borde por dataset
  geom_histogram(aes(y = after_stat(density),
                     fill = Dataset,
                     color = Dataset),
                 bins = 50,
                 position = "identity",
                 alpha = 0.30,
                 linewidth = 0.6) +
  
  # Densidades solo línea
  geom_density(aes(color = Dataset),
               linewidth = 1.2, alpha=0.5 ) +
  
  scale_fill_manual(values = c("Antes" = "pink",
                               "Después" = "#BAC095")) +
  
  scale_color_manual(values = c("Antes" = "firebrick",
                                "Después" = "#5A6E3A")) +
  
  labs(title = "Comparación de MntRegularProds antes y después de la corrección",
       x = "Monto (MntRegularProds)",
       y = "Densidad",
       fill = "Dataset",
       color = "Dataset") +
  
  theme_minimal()

dist_mntregular


```


En la Figura \@ref(fig:comparacionmntregularfinal) se observa una superposición prácticamente total entre las distribuciones. Incluso con la diferenciación por color y leyenda, no se distinguen variaciones visuales relevantes entre el conjunto original y el corregido.

```{r exportacion-data-consistente, include=FALSE}
# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET DEPURADO
# -------------------------------------------------------------------------
write.csv(
  data_consistente,
  file = "data_limpia/data_consistente.csv",
  row.names = FALSE
)
# Se exporta el nuevo dataset consistente en formato CSV
```


## Identificación de datos faltantes

En esta etapa se cuantifica la presencia de valores nulos en tres momentos clave del proceso de limpieza. Este ejercicio permite verificar si la depuración de duplicados o la corrección de inconsistencias alteraron la estructura de los datos faltantes.

```{r nuloscomparativa, echo=FALSE}
# -------------------------------------------------------------------------
# FUNCIÓN PARA CALCULAR TABLAS DE NULOS
# -------------------------------------------------------------------------

# Se define una función reutilizable que recibe un data frame,
# calcula la cantidad y proporción de valores NA por variable
# y retorna únicamente aquellas variables que presentan al menos un faltante.

calcular_nulos <- function(df) {
  data.frame(
    Variable = names(df),
    Nulos = colSums(is.na(df)),
    Porcentaje = round(colSums(is.na(df)) / nrow(df) * 100, 2)
  ) %>%
    filter(Nulos > 0) %>%
    arrange(desc(Porcentaje))
}

# -------------------------------------------------------------------------
# CÁLCULO DE NULOS EN LAS TRES ETAPAS DEL PROCESO DE LIMPIEZA
# -------------------------------------------------------------------------

# Etapa 1: Dataset original (lectura directa del archivo fuente)
raw_data <- readxl::read_xlsx("data/data_actividad1.xlsx")
tabla_nulos_original <- calcular_nulos(raw_data)

# Etapa 2: Dataset tras la eliminación de duplicados
data_sin_dup <- read.csv("data_limpia/data_sin_duplicados.csv")
tabla_nulos_sin_dup <- calcular_nulos(data_sin_dup)

# Etapa 3: Dataset tras la corrección de inconsistencias
tabla_nulos_consistente <- calcular_nulos(data_consistente)

# -------------------------------------------------------------------------
# CONSTRUCCIÓN DE LA TABLA COMPARATIVA
# -------------------------------------------------------------------------

# Se genera un vector con las variables que presentan faltantes
# en al menos una de las tres etapas

vars_con_na <- unique(c(
  tabla_nulos_original$Variable,
  tabla_nulos_sin_dup$Variable,
  tabla_nulos_consistente$Variable
))

# Se construye la tabla comparativa unificada mediante left_join
# Cada columna representa una etapa del proceso de limpieza

tabla_comparativa_nulos <- data.frame(Variable = vars_con_na) %>%
  left_join(
    tabla_nulos_original %>% select(Variable, Nulos_orig = Nulos, Pct_orig = Porcentaje),
    by = "Variable"
  ) %>%
  left_join(
    tabla_nulos_sin_dup %>% select(Variable, Nulos_dedup = Nulos, Pct_dedup = Porcentaje),
    by = "Variable"
  ) %>%
  left_join(
    tabla_nulos_consistente %>% select(Variable, Nulos_final = Nulos, Pct_final = Porcentaje),
    by = "Variable"
  ) %>%
  # Se reemplazan los NA resultantes del join por 0
  # (indica que la variable no tenía faltantes en esa etapa)
  mutate(across(where(is.numeric), ~ replace_na(.x, 0)))
```

La Tabla \@ref(tab:tablanulos) presenta la evolución de los datos faltantes en cada etapa del proceso de depuración: dataset original (n = `r nrow(raw_data)`), tras la eliminación de duplicados (n = `r nrow(data_sin_dup)`) y tras la corrección de inconsistencias (n = `r nrow(data_consistente)`).

```{r tablanulos, echo=FALSE}
knitr::kable(
  tabla_comparativa_nulos,
  format = "html",
  caption = "Evolución de datos faltantes por etapa de depuración",
  col.names = c(
    "Variable",
    "NA", "(%)",
    "NA", "(%)",
    "NA", "(%)"
  ),
  align = c("l", rep("r", 6))
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  add_header_above(c(
    " " = 1,
    "Original" = 2,
    "Sin duplicados" = 2,
    "Consistente" = 2
  )) %>%
  column_spec(1, bold = TRUE)
```

Como se observa en la Tabla \@ref(tab:tablanulos), los datos faltantes se concentran exclusivamente en las variables **Income** y **MntWines** a lo largo de las tres etapas. La eliminación de duplicados redujo ligeramente las cantidades absolutas, mientras que la corrección de inconsistencias (remoción de 2 registros con edades no plausibles) no alteró el conteo de faltantes. En el dataset final de trabajo (n = `r nrow(data_consistente)`), **Income** presenta `r tabla_nulos_consistente$Nulos[tabla_nulos_consistente$Variable == "Income"]` valores faltantes (`r tabla_nulos_consistente$Porcentaje[tabla_nulos_consistente$Variable == "Income"]`%) y **MntWines** registra `r tabla_nulos_consistente$Nulos[tabla_nulos_consistente$Variable == "MntWines"]` (`r tabla_nulos_consistente$Porcentaje[tabla_nulos_consistente$Variable == "MntWines"]`%).

Para identificar posibles patrones de co-ausencia, la Figura \@ref(fig:aggrfaltantes) muestra el gráfico de agregación. Las barras de la izquierda indican la proporción de faltantes por variable, mientras que la matriz de la derecha señala si existen registros que carecen de información en múltiples variables simultáneamente.

```{r aggrfaltantes, fig.cap="Gráfico de agregación: Proporción de nulos y combinaciones de co-ausencia.", echo=FALSE, results="hide", fig.width=10, fig.height=8}
VIM::aggr(
  data_consistente,
  col = c("pink", "firebrick"), 
  numbers = TRUE,
  prop = FALSE,
  cex.numbers = 0.8,
  sortVars = TRUE,
  labels = names(data_consistente),
  cex.axis = 0.7,
  las = 2,
  gap = 3,
  combined = FALSE,
  ylab = c("Proporción de datos", "Conteo de faltantes")
)
```

Finalmente, la Figura \@ref(fig:missingmap) presenta el mapa de valores faltantes, que permite observar la distribución espacial de los vacíos a lo largo de todas las observaciones del dataset.

```{r missingmap, fig.width=12, fig.height=6, fig.cap="Mapa de valores faltantes (Matriz de presencia espacial).", echo=FALSE}
vis_miss(data_consistente, sort_miss = TRUE) 
```

La revisión conjunta de las Figuras \@ref(fig:aggrfaltantes) y \@ref(fig:missingmap) confirma que los faltantes aparecen de forma dispersa, sin patrones estructurados de co-ausencia: la ausencia en *Income* no está ligada a la de *MntWines*. Ambas proporciones se sitúan por debajo del 5% (Little y Rubin, 2002), por lo que se espera un impacto limitado sobre los análisis posteriores.

## Tratamiento de datos faltantes

### Evaluación de la aleatoriedad de los datos faltantes

Antes de proceder con la imputación, resulta necesario determinar si los datos faltantes siguen un patrón completamente aleatorio (MCAR) o si, por el contrario, su ausencia está asociada a otras variables del conjunto de datos. Para ello, se aplica el test de Little (1988), incluyendo un conjunto amplio de variables potencialmente relacionadas con la probabilidad de ausencia: ingresos, gasto en vinos, edad, composición del hogar, antigüedad, frecuencia de compras y variables demográficas reconstruidas como factores.

```{r test-mcar, echo=FALSE}
# -------------------------------------------------------------------------
# TEST DE LITTLE PARA EVALUACIÓN DEL MECANISMO MCAR
# -------------------------------------------------------------------------

# Se reconstruyen las variables categóricas originales a partir de las dummies,
# dado que el test requiere variables con estructura factorial para evaluar
# patrones de ausencia condicional

datos_little <- data_consistente %>%
  mutate(
    Education = case_when(
      education_PhD == 1 ~ "PhD",
      education_Master == 1 ~ "Master",
      education_Graduation == 1 ~ "Graduation",
      education_Basic == 1 ~ "Basic",
      education_2n.Cycle == 1 ~ "2n Cycle",
      TRUE ~ NA_character_
    ),
    Marital = case_when(
      marital_Divorced == 1 ~ "Divorced",
      marital_Married == 1 ~ "Married",
      marital_Single == 1 ~ "Single",
      marital_Together == 1 ~ "Together",
      marital_Widow == 1 ~ "Widow",
      TRUE ~ NA_character_
    )
  ) %>%
  select(Income, MntWines, Age, Kidhome, Teenhome, Recency,
         NumWebPurchases, NumStorePurchases, NumCatalogPurchases,
         Education, Marital)

# Conversión a factores para el test
datos_little$Education <- factor(datos_little$Education)
datos_little$Marital <- factor(datos_little$Marital)

# Ejecución del test de Little
test_little <- naniar::mcar_test(datos_little)

# Presentación del resultado
knitr::kable(
  data.frame(
    Estadístico = round(test_little$statistic, 4),
    gl = test_little$df,
    p_valor = round(test_little$p.value, 4)
  ),
  format = "html",
  caption = "Resultado del test de Little para MCAR"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  )
```

La Tabla \@ref(tab:test-mcar) presenta el resultado del test de Little, cuyas hipótesis son:

$$H_0: \text{Los datos faltantes son MCAR (completamente al azar)}$$
$$H_1: \text{Los datos faltantes NO son MCAR}$$

Dado el p-valor = `r round(test_little$p.value, 4)` < 0.05, se rechaza $H_0$: los datos no siguen un mecanismo MCAR. Ante el bajo porcentaje de ausencia (<5%) y la ausencia de evidencia que sugiera MNAR, se asume un mecanismo MAR y se procede con imputación múltiple (Rubin, 1987).

### Preparación del conjunto de datos para imputación

Antes de imputar, se excluyen las variables que son combinaciones lineales de otras (*MntTotal*, *MntRegularProds* y *AcceptedCmpOverall*) para evitar multicolinealidad perfecta en el algoritmo. Estas serán recalculadas tras la imputación.

```{r eliminar-redundante, echo=FALSE}
# -------------------------------------------------------------------------
# EXCLUSIÓN DE VARIABLES LINEALMENTE DEPENDIENTES
# -------------------------------------------------------------------------

# Se eliminan variables derivadas para evitar singularidad
# en la matriz de predicción del algoritmo de imputación

datos_imputacion <- data_consistente %>%
  select(-MntRegularProds, -MntTotal, -AcceptedCmpOverall)
```
### Comparación de métodos de imputación

Se evalúan tres métodos de imputación múltiple, cada uno con $m = 5$ imputaciones y 10 iteraciones: PMM (*Predictive Mean Matching*) con regularización ridge, CART (*Classification and Regression Trees*) y regresión ridge. En todos los casos se emplea un subconjunto de variables predictoras seleccionadas por su relevancia teórica y su capacidad explicativa.

```{r imputacion-metodos, echo=FALSE}
# -------------------------------------------------------------------------
# DEFINICIÓN DE VARIABLES PREDICTORAS Y EJECUCIÓN DE IMPUTACIONES
# -------------------------------------------------------------------------

# Subconjunto de variables relevantes para la imputación
vars_predictoras <- c(
  "Age", "Customer_Days", "Recency",
  "NumWebPurchases", "NumCatalogPurchases", "NumStorePurchases",
  "NumWebVisitsMonth", "NumDealsPurchases",
  "Kidhome", "Teenhome",
  "marital_Married", "marital_Single",
  "education_Graduation", "education_Master", "education_PhD",
  "MntMeatProducts", "MntWines", "Income"
)

datos_imp_subset <- datos_imputacion %>%
  select(all_of(vars_predictoras))

# Método 1: PMM con regularización ridge
imp_pmm <- mice(datos_imp_subset, m = 5, method = "pmm",
                ridge = 1e-4, maxit = 10, seed = 42, printFlag = FALSE)

# Método 2: CART (árboles de clasificación y regresión)
imp_cart <- mice(datos_imp_subset, m = 5, method = "cart",
                 maxit = 10, seed = 42, printFlag = FALSE)

# Método 3: Regresión ridge
metodos <- make.method(datos_imp_subset)
metodos["Income"] <- "norm"
metodos["MntWines"] <- "norm"
predictor_matrix <- make.predictorMatrix(datos_imp_subset)
diag(predictor_matrix) <- 0

imp_ridge <- mice(datos_imp_subset, m = 5, method = metodos,
                  predictorMatrix = predictor_matrix,
                  ridge = 1e-3, maxit = 10, seed = 42, printFlag = FALSE)
```

Para seleccionar el método que mejor preserva la estructura de los datos observados, se evalúan tres criterios: estabilidad de las imputaciones (desviación estándar de las medias entre las 5 réplicas), preservación de momentos (comparación de medias y desviaciones estándar con los datos observados) y preservación de correlaciones.

#### Criterio 1: Estabilidad de las imputaciones

La Tabla \@ref(tab:tabla-estabilidad) presenta la desviación estándar de las medias imputadas entre las 5 réplicas para cada método. Un valor menor indica mayor estabilidad, es decir, que las distintas imputaciones producen resultados más consistentes entre sí.

```{r tabla-estabilidad, echo=FALSE}
# -------------------------------------------------------------------------
# FUNCIÓN PARA EXTRAER ESTADÍSTICOS DE IMPUTACIÓN
# -------------------------------------------------------------------------

estadisticos_imputacion <- function(imp, metodo_nombre) {
  completed <- complete(imp, "long")
  
  stats_income <- completed %>%
    group_by(.imp) %>%
    summarise(media_income = mean(Income, na.rm = TRUE),
              sd_income = sd(Income, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media = mean(media_income),
              sd_media = sd(media_income),
              media_sd = mean(sd_income))
  
  stats_wines <- completed %>%
    group_by(.imp) %>%
    summarise(media_wines = mean(MntWines, na.rm = TRUE),
              sd_wines = sd(MntWines, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media_w = mean(media_wines),
              sd_media_w = sd(media_wines),
              media_sd_w = mean(sd_wines))
  
  data.frame(
    Metodo = metodo_nombre,
    Income_media = stats_income$media_media,
    Income_sd = stats_income$media_sd,
    Income_sd_entre = stats_income$sd_media,
    MntWines_media = stats_wines$media_media_w,
    MntWines_sd = stats_wines$media_sd_w,
    MntWines_sd_entre = stats_wines$sd_media_w
  )
}

# Estadísticos observados (casos completos como referencia)
obs_stats <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  summarise(
    Income_media_obs = mean(Income),
    Income_sd_obs = sd(Income),
    MntWines_media_obs = mean(MntWines),
    MntWines_sd_obs = sd(MntWines)
  )

# Compilación de resultados por método
comp_metodos <- bind_rows(
  estadisticos_imputacion(imp_pmm, "PMM"),
  estadisticos_imputacion(imp_cart, "CART"),
  estadisticos_imputacion(imp_ridge, "Ridge")
)

# Cálculo de diferencias relativas respecto a los datos observados
comp_metodos <- comp_metodos %>%
  mutate(
    Income_diff_media = abs(Income_media - obs_stats$Income_media_obs) /
      obs_stats$Income_media_obs * 100,
    Income_diff_sd = abs(Income_sd - obs_stats$Income_sd_obs) /
      obs_stats$Income_sd_obs * 100,
    Wines_diff_media = abs(MntWines_media - obs_stats$MntWines_media_obs) /
      obs_stats$MntWines_media_obs * 100,
    Wines_diff_sd = abs(MntWines_sd - obs_stats$MntWines_sd_obs) /
      obs_stats$MntWines_sd_obs * 100
  )

# -------------------------------------------------------------------------
# TABLA 1: ESTABILIDAD (sd entre réplicas — menor es mejor)
# -------------------------------------------------------------------------

tab_estab <- comp_metodos %>%
  select(Metodo, Income_sd_entre, MntWines_sd_entre)

# Identificar el mejor (mínimo) por columna y colorear en firebrick
tab_estab_fmt <- tab_estab %>%
  mutate(
    Income_sd_entre = cell_spec(
      round(Income_sd_entre, 2), "html",
      color = ifelse(Income_sd_entre == min(Income_sd_entre), "firebrick", "black"),
      bold = ifelse(Income_sd_entre == min(Income_sd_entre), TRUE, FALSE)
    ),
    MntWines_sd_entre = cell_spec(
      round(MntWines_sd_entre, 2), "html",
      color = ifelse(MntWines_sd_entre == min(MntWines_sd_entre), "firebrick", "black"),
      bold = ifelse(MntWines_sd_entre == min(MntWines_sd_entre), TRUE, FALSE)
    )
  )

knitr::kable(
  tab_estab_fmt,
  format = "html",
  escape = FALSE,
  caption = "Estabilidad de las imputaciones: desviación estándar de las medias entre réplicas",
  col.names = c("Método", "SD entre réplicas (Income)", "SD entre réplicas (MntWines)")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

#### Criterio 2: Preservación de momentos

La Tabla \@ref(tab:tabla-momentos) compara las diferencias relativas entre las medias y desviaciones estándar imputadas y las observadas en los datos completos. Un valor menor indica que el método distorsiona menos la distribución original.

```{r tabla-momentos, echo=FALSE}
# -------------------------------------------------------------------------
# TABLA 2: PRESERVACIÓN DE MOMENTOS (diff relativa — menor es mejor)
# -------------------------------------------------------------------------

tab_mom <- comp_metodos %>%
  select(Metodo, Income_diff_media, Income_diff_sd, Wines_diff_media, Wines_diff_sd)

tab_mom_fmt <- tab_mom %>%
  mutate(
    Income_diff_media = cell_spec(
      round(Income_diff_media, 2), "html",
      color = ifelse(Income_diff_media == min(Income_diff_media), "firebrick", "black"),
      bold = ifelse(Income_diff_media == min(Income_diff_media), TRUE, FALSE)
    ),
    Income_diff_sd = cell_spec(
      round(Income_diff_sd, 2), "html",
      color = ifelse(Income_diff_sd == min(Income_diff_sd), "firebrick", "black"),
      bold = ifelse(Income_diff_sd == min(Income_diff_sd), TRUE, FALSE)
    ),
    Wines_diff_media = cell_spec(
      round(Wines_diff_media, 2), "html",
      color = ifelse(Wines_diff_media == min(Wines_diff_media), "firebrick", "black"),
      bold = ifelse(Wines_diff_media == min(Wines_diff_media), TRUE, FALSE)
    ),
    Wines_diff_sd = cell_spec(
      round(Wines_diff_sd, 2), "html",
      color = ifelse(Wines_diff_sd == min(Wines_diff_sd), "firebrick", "black"),
      bold = ifelse(Wines_diff_sd == min(Wines_diff_sd), TRUE, FALSE)
    )
  )

knitr::kable(
  tab_mom_fmt,
  format = "html",
  escape = FALSE,
  caption = "Preservación de momentos: diferencia relativa (%) respecto a datos observados",
  col.names = c("Método", "Δ% Media Income", "Δ% SD Income",
                "Δ% Media MntWines", "Δ% SD MntWines")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

#### Criterio 3: Preservación de correlaciones

La Tabla \@ref(tab:tabla-cor) compara las correlaciones de Pearson entre *Income*, *MntWines* y *Age* para cada método (promedio de las 5 imputaciones) frente a la correlación observada en los datos completos. Se resalta en color el método cuya correlación es más cercana a la observada en cada par de variables.

```{r tabla-cor, echo=FALSE}
# -------------------------------------------------------------------------
# COMPARACIÓN DE CORRELACIONES ENTRE MÉTODOS
# -------------------------------------------------------------------------

# Correlación observada (casos completos)
obs_cor <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  select(Income, MntWines, Age) %>%
  cor(use = "complete.obs")

# Función para calcular correlaciones promedio de las m imputaciones
cor_method <- function(imp) {
  completed <- complete(imp, "long")
  cors <- completed %>%
    group_by(.imp) %>%
    summarise(cor_inc_wine = cor(Income, MntWines, use = "complete.obs"),
              cor_inc_age = cor(Income, Age, use = "complete.obs"),
              cor_wine_age = cor(MntWines, Age, use = "complete.obs")) %>%
    ungroup() %>%
    summarise(across(starts_with("cor"), mean))
  as.numeric(cors)
}

cor_pmm <- cor_method(imp_pmm)
cor_cart <- cor_method(imp_cart)
cor_ridge <- cor_method(imp_ridge)

# Valores observados de referencia
obs_vals <- c(obs_cor["Income","MntWines"], obs_cor["Income","Age"], obs_cor["MntWines","Age"])

# Construir tabla de correlaciones (solo métodos, sin fila observado todavía)
cor_mat <- rbind(cor_pmm, cor_cart, cor_ridge)
metodo_names <- c("PMM", "CART", "Ridge")

# Calcular diferencia absoluta respecto a la observada por cada par
diff_mat <- abs(sweep(cor_mat, 2, obs_vals))

# Identificar el método con menor diferencia por columna
mejor_por_col <- apply(diff_mat, 2, which.min)

# Construir data.frame con formato
tabla_cor_fmt <- data.frame(
  Metodo = c("Observado", metodo_names),
  stringsAsFactors = FALSE
)

for (j in 1:3) {
  col_obs <- round(obs_vals[j], 3)
  col_vals <- round(cor_mat[, j], 3)
  
  # Fila observado sin color especial
  formatted <- c(as.character(col_obs))
  
  # Filas de métodos: colorear el mejor
  for (i in 1:3) {
    if (i == mejor_por_col[j]) {
      formatted <- c(formatted,
        cell_spec(col_vals[i], "html", color = "firebrick", bold = TRUE))
    } else {
      formatted <- c(formatted, as.character(col_vals[i]))
    }
  }
  
  tabla_cor_fmt[[paste0("V", j)]] <- formatted
}

names(tabla_cor_fmt)[2:4] <- c("Income ~ MntWines", "Income ~ Age", "MntWines ~ Age")

knitr::kable(
  tabla_cor_fmt,
  format = "html",
  escape = FALSE,
  caption = "Correlaciones promedio (5 imputaciones) comparadas con las observadas"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(1, background = "#f0f0f0", italic = TRUE)
```

<!-- ================================================================== -->
<!-- JUSTIFICACIÓN PENDIENTE: la redacción interpretativa de estas      -->
<!-- tablas se completará en una etapa posterior.                        -->
<!-- ================================================================== -->

Con base en los resultados de las Tablas \@ref(tab:tabla-estabilidad), \@ref(tab:tabla-momentos) y \@ref(tab:tabla-cor), se selecciona **CART** como método final de imputación.

### Verificación de estabilidad y construcción del dataset imputado

Para confirmar que las cinco imputaciones generadas por CART producen resultados consistentes, la Tabla \@ref(tab:consistencia-imputaciones) presenta las medias de *Income* y *MntWines* en cada una de las réplicas.

```{r consistencia-imputaciones, echo=FALSE}
# -------------------------------------------------------------------------
# VERIFICACIÓN DE CONSISTENCIA ENTRE IMPUTACIONES (CART)
# -------------------------------------------------------------------------

completed_cart <- complete(imp_cart, "long")

medias_por_imp <- completed_cart %>%
  group_by(.imp) %>%
  summarise(
    Media_Income = mean(Income),
    Media_MntWines = mean(MntWines)
  )

knitr::kable(
  medias_por_imp,
  digits = 2,
  format = "html",
  col.names = c("Imputación", "Media Income", "Media MntWines"),
  caption = "Medias por imputación (CART): verificación de estabilidad"
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE)
```

La baja variabilidad entre imputaciones confirma la estabilidad del método. Se utiliza la primera imputación para la construcción del dataset final, sobre el cual se recalculan las variables derivadas previamente excluidas.

```{r construccion-dataset-final, echo=FALSE}
# -------------------------------------------------------------------------
# CONSTRUCCIÓN DEL DATASET FINAL IMPUTADO (CART)
# -------------------------------------------------------------------------

# Se extrae la primera imputación del objeto CART
datos_final_subset <- complete(imp_cart, 1)

# Se reemplazan las variables imputadas en el dataset completo
datos_final <- datos_imputacion
datos_final$Income <- datos_final_subset$Income
datos_final$MntWines <- datos_final_subset$MntWines

# Recálculo de variables derivadas con las fórmulas verificadas
# en la sección de corrección de inconsistencias
datos_final <- datos_final %>%
  mutate(
    MntTotal = MntWines + MntFruits + MntMeatProducts +
               MntFishProducts + MntSweetProducts + MntGoldProds,
    MntRegularProds = MntWines + MntFruits + MntMeatProducts +
                      MntFishProducts + MntSweetProducts,
    AcceptedCmpOverall = AcceptedCmp1 + AcceptedCmp2 + AcceptedCmp3 +
                         AcceptedCmp4 + AcceptedCmp5
  )
```

### Comparación de estadísticos antes y después de la imputación

La Tabla \@ref(tab:antes-despues) presenta los principales estadísticos descriptivos de *Income* y *MntWines* calculados antes de la imputación (sobre los datos observados, excluyendo NA) y después de la imputación (sobre el dataset completo). Esta comparación permite verificar que el método CART no introdujo distorsiones relevantes en la estructura de los datos.

<div style="overflow-x: auto; width: 100%;">
```{r antes-despues, echo=FALSE}
# -------------------------------------------------------------------------
# TABLA COMPARATIVA: ESTADÍSTICOS ANTES Y DESPUÉS DE IMPUTACIÓN
# -------------------------------------------------------------------------

# Función para calcular estadísticos descriptivos de una variable
calc_stats <- function(x, etiqueta) {
  data.frame(
    Etapa = etiqueta,
    Min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    Mediana = median(x, na.rm = TRUE),
    Media = round(mean(x, na.rm = TRUE), 2),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    Max = max(x, na.rm = TRUE),
    SD = round(sd(x, na.rm = TRUE), 2),
    n = sum(!is.na(x)),
    row.names = NULL
  )
}

# Income: antes y después
stats_income_antes <- calc_stats(data_consistente$Income, "Antes (observados)")
stats_income_despues <- calc_stats(datos_final$Income, "Después (imputado)")
tab_income <- bind_rows(stats_income_antes, stats_income_despues)

# MntWines: antes y después
stats_wines_antes <- calc_stats(data_consistente$MntWines, "Antes (observados)")
stats_wines_despues <- calc_stats(datos_final$MntWines, "Después (imputado)")
tab_wines <- bind_rows(stats_wines_antes, stats_wines_despues)

# Tabla combinada
tab_ad <- bind_rows(
  tab_income %>% mutate(Variable = "Income"),
  tab_wines %>% mutate(Variable = "MntWines")
) %>%
  select(Variable, Etapa, n, Min, Q1, Mediana, Media, Q3, Max, SD)

knitr::kable(
  tab_ad,
  format = "html",
  caption = "Estadísticos descriptivos de Income y MntWines antes y después de la imputación",
  col.names = c("Variable", "Etapa", "n", "Mín", "Q1", "Mediana",
                "Media", "Q3", "Máx", "SD"),
  align = c("l", "l", rep("r", 8))
) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    full_width = FALSE
  ) %>%
  column_spec(1, bold = TRUE) %>%
  collapse_rows(columns = 1, valign = "middle")
```
</div>


También se puede confirmar que la imputación no haya distorsionado las distribuciones originales revisando la Figura \@ref(fig:densidad-compa) que también compara las curvas de densidad de *Income* y *MntWines* antes y después de la imputación.

```{r densidad-compa, echo=FALSE, fig.cap="Densidades originales vs. imputadas para Income y MntWines.", fig.width=12, fig.height=5}
# -------------------------------------------------------------------------
# COMPARACIÓN DE DENSIDADES PRE Y POST IMPUTACIÓN
# -------------------------------------------------------------------------

# Se desactiva temporalmente ggthemr para controlar la paleta de colores
ggthemr_reset()

p1 <- ggplot() +
  geom_density(data = data_consistente,
               aes(x = Income, color = "Original (con NA)"),
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final,
               aes(x = Income, color = "Imputado"),
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original (con NA)" = "#5A6E3A", "Imputado" = "firebrick")
  ) +
  labs(title = "Income: Original vs. Imputado",
       x = "Ingreso anual", y = "Densidad") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "bottom")

p2 <- ggplot() +
  geom_density(data = data_consistente,
               aes(x = MntWines, color = "Original (con NA)"),
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final,
               aes(x = MntWines, color = "Imputado"),
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original (con NA)" = "#5A6E3A", "Imputado" = "firebrick")
  ) +
  labs(title = "MntWines: Original vs. Imputado",
       x = "Monto en vinos", y = "Densidad") +
  theme_minimal() +
  theme(plot.title = element_text(size = 10, face = "bold"),
        legend.position = "bottom")

grid.arrange(p1, p2, ncol = 2)

# Se restaura el tema global para los chunks posteriores
ggthemr("dust", layout = "clean")
```

Las curvas muestran una superposición prácticamente completa, sin distorsiones visibles en la forma ni en la localización de las distribuciones. 

```{r exportacion-datos-final, include=FALSE}
# -------------------------------------------------------------------------
# EXPORTACIÓN DEL DATASET FINAL IMPUTADO
# -------------------------------------------------------------------------
write.csv(
  datos_final,
  file = "data_limpia/data_final_imputada.csv",
  row.names = FALSE
)
```


